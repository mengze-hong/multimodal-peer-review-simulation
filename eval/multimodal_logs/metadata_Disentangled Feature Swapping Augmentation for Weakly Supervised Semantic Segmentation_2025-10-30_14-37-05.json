{
  "title": "Disentangled Feature Swapping Augmentation for Weakly Supervised Semantic Segmentation",
  "abstract": "Weakly supervised semantic segmentation utilizes a localization map obtained\nfrom a classifier to generate a pseudo-mask. However, classifiers utilize back-\nground cues to predict class labels because of a biased dataset consisting of im-\nages, in which specific objects frequently co-occur with certain backgrounds.",
  "summary": "### Overview of the Paper: Disentangled Feature Swapping Augmentation (DEFT) for Weakly Supervised Semantic Segmentation (WSSS)\n\nThe paper, under review for ICLR 2023, introduces **Disentangled Feature Swapping Augmentation (DEFT)**, a novel method designed to address the limitations of weakly supervised semantic segmentation (WSSS). WSSS relies on localization maps, such as Class Activation Maps (CAMs), generated by classifiers trained on image-level class labels. However, these classifiers often confuse target objects with background due to dataset biases, where specific objects frequently co-occur with certain backgrounds (e.g., sheep with grass). This results in inaccurate CAMs and pseudo-masks, hindering segmentation performance.\n\n---\n\n### Key Contributions\n\n1. **DEFT Method**:\n   - **Feature Disentanglement**: DEFT separates foreground (class-relevant) and background (class-irrelevant) features, which are often entangled in traditional methods.\n   - **Feature Swapping**: Disentangled features are randomly swapped within mini-batches, breaking the dependency between objects and specific backgrounds. This augmentation introduces diverse contextual information while preserving class-relevant features.\n   - **Classifier Design**: Two classifiers are trained—one for foreground features and another for background features—to ensure effective separation and learning of distinct attributes.\n\n2. **Advantages**:\n   - Operates in the feature space, avoiding heuristic decisions or network re-training.\n   - Easily integrates into existing WSSS pipelines.\n   - Reduces spurious correlations between objects and frequent backgrounds, enabling classifiers to focus on target objects.\n\n3. **Pseudo-Mask Generation**:\n   - DEFT uses disentangled features to generate high-quality localization maps, which are refined into pseudo-masks for segmentation training.\n\n---\n\n### Background and Related Work\n\n#### Weakly Supervised Semantic Segmentation (WSSS)\n- WSSS reduces annotation costs by using weak labels (e.g., image-level class labels) instead of pixel-level labels.\n- CAM-based methods generate pseudo-masks from localization maps, but these are often biased due to dataset correlations (e.g., sheep-grass, boat-water).\n- Existing methods like AdvCAM, DRS, and SEAM aim to expand object regions in CAMs, while others like SIPE and ICD address misleading correlations using additional supervision or prototype modeling.\n\n#### Data Augmentation\n- Traditional methods like **Mixup** and **CutMix** interpolate or replace image regions but often confuse classifiers by occluding both foreground and background.\n- Saliency-based methods focus on salient regions but fail to teach classifiers about non-discriminative regions or background cues.\n- Feature space augmentation methods, such as **Manifold Mixup**, enhance diversity but do not explicitly address object-background entanglement.\n- **Context Decoupling Augmentation (CDA)** separates object and context but relies on single-class images and restricts mask scales, limiting diversity.\n\n---\n\n### Proposed Method: DEFT\n\n#### Key Components\n1. **Feature Disentanglement**:\n   - Foreground features (`z_fg`) are class-relevant, while background features (`z_bg`) are class-irrelevant.\n   - Two classifiers (`f_fg` and `f_bg`) are trained with opposite labels for `z_fg` and `z_bg` to ensure separation.\n   - A disentanglement loss is used to train the classifiers:\n     \\[\n     L_{disen} = BCE(f_{fg}(z_{fg}), y) + \\lambda BCE(f_{fg}(z_{bg}), 1-y) + \\lambda BCE(f_{bg}(z_{fg}), 0) + \\lambda BCE(f_{bg}(z_{bg}), 1)\n     \\]\n     where \\(\\lambda = 0.3\\).\n\n2. **Feature Swapping**:\n   - Disentangled features are swapped within mini-batches to address dataset bias:\n     - Combine class-relevant foreground features with randomly permuted background features.\n     - Combine class-irrelevant background features with randomly permuted foreground features.\n   - A swapping loss ensures consistent predictions despite swapped features:\n     \\[\n     L_{swap} = BCE(f_{swap}(z_{swap\\_bg}), y) + BCE(f_{swap}(z_{swap\\_fg}), \\bar{y})\n     \\]\n   - The total loss combines disentanglement and swapping losses:\n     \\[\n     L = L_{disen} + L_{swap}\n     \\]\n\n3. **Pseudo-Mask Generation**:\n   - Class Activation Maps (CAMs) are generated using disentangled features to localize class-relevant regions.\n   - The localization map combines activation maps for foreground and background:\n     \\[\n     P = \\max(w_{fg}^T z, 1 - w_{bg}^T z)\n     \\]\n   - Refinement methods (e.g., IRN) produce high-resolution pseudo-masks for segmentation training.\n\n---\n\n### Experimental Results\n\n#### Implementation Details\n- **Dataset**: Pascal VOC 2012 with 21 classes (20 objects + 1 background).\n- **Classifier**: ResNet-50 pretrained on ImageNet.\n- **Training**: Learning rate initialized at 0.1, decayed using a polynomial function. Feature swapping was applied after disentanglement was achieved (epoch 6).\n\n#### Performance Improvements\n1. **Localization Maps**:\n   - DEFT improved mIoU across various WSSS methods:\n     - PSA: 48.0 → 51.6\n     - IRN: 48.3 → 52.3\n     - AdvCAM: 55.6 → 57.0\n     - AMN: 62.1 → 64.3\n   - Outperformed other augmentation methods (e.g., Mixup, CutMix, CDA).\n\n2. **Pseudo-Masks and Segmentation**:\n   - Improved pseudo-mask mIoU for all baselines:\n     - PSA: 61.0 → 64.2\n     - IRN: 66.3 → 68.6\n     - AMN: 72.2 → 72.8\n   - Enhanced segmentation network performance on validation and test sets.\n\n3. **Reduction of Spurious Correlations**:\n   - DEFT reduced harmful correlations between objects and frequent backgrounds (e.g., aeroplane-sky, sheep-grass).\n\n4. **Ablation Study**:\n   - Adding disentanglement loss improved mIoU by +1.8%p.\n   - Adding swapping losses further improved mIoU to 52.3%.\n\n#### Visualization\n- T-SNE visualizations confirmed that DEFT effectively disentangles foreground and background features, making them semantically distinct.\n\n---\n\n### Advantages of DEFT\n- Operates at the feature level, enabling diverse and automated representation learning without manual mask design.\n- Reduces reliance on spurious correlations, improving generalization and robustness.\n- Enhances localization maps, pseudo-masks, and segmentation performance, outperforming existing augmentation methods.\n\n---\n\n### Conclusion and Future Work\nDEFT addresses the limitations of existing WSSS methods by disentangling and swapping foreground and background features, leading to improved classifier performance and representation diversity. Future work will explore incorporating metric learning to further enhance feature disentanglement.",
  "ref": {
    "weaknesses": [
      "Lack of clarity in the explanation of novel contributions and their differentiation from existing methods.",
      "Insufficient theoretical grounding to support experimental findings.",
      "Experimental results are not convincingly presented, lacking comprehensive analysis or statistical validation.",
      "Ambiguity in methodological descriptions, leading to confusion about implementation details.",
      "Over-reliance on standard baselines without exploring applicability to more recent architectures."
    ],
    "improvements": [
      "Enhance clarity by clearly defining key terms and concepts, and explicitly differentiating proposed methods from existing ones.",
      "Provide stronger theoretical justifications for the proposed methods to support experimental outcomes.",
      "Include comprehensive experimental validation, such as confidence intervals or standard errors, to strengthen the reliability of results.",
      "Ensure clear and detailed methodological descriptions to facilitate reproducibility and understanding.",
      "Explore the applicability of the proposed methods to a wider range of datasets and more recent architectures to demonstrate generalizability."
    ]
  },
  "rev": "**1. Summary**  \nThe paper introduces Disentangled Feature Swapping Augmentation (DEFT), a novel approach for improving weakly supervised semantic segmentation (WSSS) by addressing the common issue of object-background entanglement in Class Activation Maps (CAMs). DEFT disentangles foreground and background features and employs feature swapping within mini-batches to reduce dataset biases, enhancing the quality of localization maps and pseudo-masks. The method integrates seamlessly into existing WSSS pipelines and demonstrates significant improvements in segmentation performance across various benchmarks, outperforming traditional augmentation methods.\n\n**2. Strengths**  \n- The paper presents a novel approach that effectively disentangles and swaps features, addressing a critical issue in WSSS.\n- DEFT is designed to be easily integrated into existing pipelines without requiring heuristic decisions or network re-training.\n- The experimental results show substantial improvements in segmentation performance, demonstrating the method's practical efficacy.\n- The paper includes a comprehensive ablation study that highlights the contributions of different components of the proposed method.\n\n**3. Weaknesses**  \n- **Clarity in Methodology**: The explanation of the disentanglement process and the role of the classifiers in Section 3.2 could be clearer. The paper should provide a more detailed description of how the classifiers are trained and how the disentanglement loss is applied. Suggestion: Include a step-by-step explanation or a flowchart to clarify the disentanglement process.\n- **Theoretical Justification**: The paper lacks a strong theoretical foundation to support the empirical results. For instance, the rationale behind the choice of the disentanglement loss function and the swapping strategy in Section 3.2 is not thoroughly justified. Suggestion: Provide theoretical insights or references to support the chosen methodologies.\n- **Baseline Comparisons**: While the paper compares DEFT with several existing methods, it does not explore its applicability to more recent architectures or datasets beyond Pascal VOC 2012. Suggestion: Include experiments on additional datasets or with newer architectures to demonstrate the generalizability of DEFT.\n- **Figure Clarity**: Some figures, such as Figure 2, lack detailed captions that explain the components and flow of the DEFT method. Suggestion: Enhance figure captions to be more descriptive and ensure they are self-explanatory.\n- **Reproducibility Details**: The paper does not provide sufficient details about the experimental setup, such as specific hyperparameters, hardware used, or random seeds, which are crucial for reproducibility. Suggestion: Include a dedicated section detailing these aspects to facilitate replication of the results.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity** – The paper is generally well-organized, with clear section titles and logical flow. However, some methodological descriptions, particularly in the disentanglement and feature swapping sections, could benefit from additional clarity and detail. Mathematical notations are well-defined, but assumptions and limitations are not explicitly discussed.\n  \n  **(b) Figure & Caption Clarity** – Figures are relevant and support the paper's claims, but some captions lack sufficient detail. For example, Figure 2 could be improved with a more comprehensive explanation of the depicted process. Axes and labels are consistent, but the correlation between diagrams and textual descriptions could be enhanced.\n  \n  **(c) Reproducibility Transparency** – The paper provides a general overview of the experimental setup but lacks specific details necessary for reproducibility, such as hyperparameters, hardware specifications, and random seeds. The inclusion of these details, along with a mention of code/data availability, would significantly enhance reproducibility.\n\n**5. Novelty & Significance**  \nDEFT introduces a novel approach to feature disentanglement and augmentation in the context of WSSS, addressing a significant challenge in the field. The method is well-motivated and contextualized within the existing literature, offering a practical solution that improves segmentation performance without requiring additional supervision or complex modifications to existing models. The empirical results substantiate the claims, demonstrating the method's effectiveness and potential impact on the community. However, the paper would benefit from stronger theoretical grounding and broader experimental validation to fully establish its significance and applicability.",
  "todo": [
    "Revise methodology explanation: Provide a clearer, step-by-step description of the disentanglement process and classifier training [Section 3.2]",
    "Add theoretical justification: Include theoretical insights or references to support the choice of the disentanglement loss function and swapping strategy [Section 3.2]",
    "Expand baseline comparisons: Conduct experiments on additional datasets or with newer architectures to demonstrate DEFT's generalizability [Section 4]",
    "Enhance figure captions: Add detailed explanations to figures, especially Figure 2, to clarify the components and flow of the DEFT method [Page 3, Figure 2]",
    "Improve reproducibility details: Include specific hyperparameters, hardware specifications, and random seeds used in experiments [Section 4]",
    "Include reproducibility section: Add a dedicated section detailing experimental setup to facilitate replication of results [Section 4]",
    "Clarify assumptions and limitations: Explicitly discuss any assumptions and limitations of the proposed method [Throughout the paper]"
  ],
  "timestamp": "2025-10-30T14:37:05.417691",
  "manuscript_file": "manuscript.pdf",
  "image_file": "concat_image.png"
}