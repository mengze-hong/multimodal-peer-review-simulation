{
  "title": "Learning to aggregate: A parameterized aggregator to debias aggregation for cross-device federated learning",
  "abstract": "Federated learning (FL) collaboratively trains deep models on decentralized\nclients with privacy constraint. The aggregation of client parameters within a com-\nmunication round suffers from the “client drift” due to the heterogeneity of client\ndata distributions, resulting in unstable and slow convergence. Recent works typ-\nically impose regularization based on the client parameters to reduce the local\naggregation heterogeneity for optimization. However, we argue that they gener-\nally neglect the inter-communication heterogeneity of data distributions (“period\ndrift”), leading to deviations of intra-communication optimization from the global\nobjective. In this work, we aim to calibrate the local aggregation under “client\ndrift” and simultaneously approach the global objective under “period drift”.",
  "summary": "### Overview of the Paper\n\nThe paper, under review for ICLR 2023, introduces **FEDPA**, a novel meta-learning-based aggregation strategy for federated learning (FL). FL enables collaborative model training across decentralized clients while preserving privacy. However, traditional aggregation methods, such as **Federated Averaging (FEDAVG)**, struggle with challenges like \"client drift\" (intra-round heterogeneity) and \"period drift\" (inter-round heterogeneity), particularly in cross-device FL with non-iid (non-independent and identically distributed) data. These challenges lead to slow convergence, performance degradation, and oscillations in model training. FEDPA addresses these issues by learning an adaptive aggregation strategy that mitigates aggregation bias and improves FL performance.\n\n---\n\n### Key Contributions\n\n1. **Problem Identification**:\n   - **Client Drift**: Variations in data distributions across clients within a single communication round, causing local updates to diverge from the global objective.\n   - **Period Drift**: Variations in data distributions across communication rounds, often overlooked in existing methods, leading to further optimization bias and instability.\n\n2. **Proposed Solution**:\n   - **Parameterized Aggregator**: FEDPA introduces a meta-learning-based aggregator that adapts to both client and period drift. Unlike static methods like FEDAVG, the aggregator is trained to optimize performance on a proxy dataset, learning to calibrate aggregation towards the global objective.\n   - **Dynamic System View**: FL is treated as a dynamic system where model parameters evolve over time. The aggregator acts as a control variable, parameterized to reduce aggregation bias and guide updates toward the global optimum.\n\n3. **Empirical Evidence**:\n   - The paper demonstrates the impact of period drift using a 10-class classification task with varying degrees of non-iid data (controlled by Dirichlet hyperparameter α). As α decreases (indicating higher non-iidness), period drift becomes more pronounced, slowing convergence and causing oscillations. FEDPA effectively mitigates these issues, outperforming baseline methods like FEDAVG.\n\n4. **Technical Framework**:\n   - FEDPA frames the aggregation process as a meta-learning task, where each communication round corresponds to a meta-task. The meta-learner captures a global view, reduces aggregation bias, and guides parameter updates toward the global objective.\n   - A **proxy dataset** (1% of training data) is used to evaluate and train the aggregator, ensuring efficient and effective learning.\n   - A **bottleneck architecture** is employed to handle high-dimensional parameters, mapping them to a low-dimensional space for efficient computation.\n\n---\n\n### Related Work\n\n1. **Federated Learning with Non-iid Data**:\n   - Existing methods like **FEDPROX** and **FedNova** address client drift using regularization or normalized averaging but fail to account for period drift.\n   - **FedBN** tackles feature shift in non-iid data using local batch normalization but does not address inter-round heterogeneity.\n\n2. **Meta-Learning**:\n   - FEDPA builds on meta-learning principles, such as **MAML** and **Reptile**, to adaptively learn aggregation strategies that generalize well across rounds.\n   - In FL, meta-learning has been applied for fast adaptation, personalization, and robustness, as seen in methods like **FedMeta**, **Meta-HAR**, and **personalized FL**.\n\n---\n\n### Methodology\n\n1. **Dynamic System and Meta-Learning**:\n   - The aggregator is trained as a meta-learner to minimize aggregation bias and guide the global model toward the optimum.\n   - The aggregation function is parameterized as:\n     \\[\n     w_{t+1} = \\text{aggr}(w_t, \\Delta W_t, \\phi)\n     \\]\n     where \\( \\Delta W_t \\) represents local updates, and \\( \\phi \\) is learned using a meta-learning framework.\n\n2. **Proxy Dataset**:\n   - A small subset (1%) of training data is used as a proxy dataset for evaluating and training the aggregator.\n\n3. **Bottleneck Architecture**:\n   - The aggregator maps high-dimensional parameters to a low-dimensional space and restores them to the original dimension for efficient computation.\n\n---\n\n### Experimental Setup\n\n1. **Datasets**:\n   - **FEMNIST**: A CV dataset with 671,585 training and 77,483 test samples across 62 classes. Model: LeNet5.\n   - **MovieLens 1M**: A recommendation dataset with 1,000,209 ratings from 6,040 users on 3,706 movies. Model: DIN.\n\n2. **FL Settings**:\n   - Non-iid data distribution simulated using Dirichlet distribution.\n   - 100 communication rounds, 10% client sampling per round, 5 local epochs per client.\n   - Proxy dataset: 1% of training data.\n   - Aggregator training: 5 epochs for MovieLens, 30 epochs for FEMNIST, with a learning rate of 0.001.\n\n3. **Baselines**:\n   - Compared against FL methods: **FedAvg**, **FedProx**, **FedAvgM**, **FedOpt**, **FedDF**, and **FedMeta**.\n   - Metrics: Top-1 accuracy for FEMNIST; AUC, Hit Ratio (HR), and NDCG for MovieLens.\n\n---\n\n### Results\n\n1. **FEMNIST (Image Classification)**:\n   - FEDPA achieves higher **Top-1 accuracy** compared to all baselines, demonstrating its effectiveness in handling non-iid data and improving convergence.\n   - At α = 0.01 (high non-iidness), FEDPA achieves 0.7224 accuracy, significantly outperforming FEDAVG (0.5427) and FEDPROX (0.5478).\n\n2. **MovieLens 1M (CTR Task)**:\n   - FEDPA outperforms baselines in **AUC**, **HR@K**, and **NDCG@K**, showing superior performance in recommendation tasks.\n   - For example, FEDPA achieves an AUC of 0.7878, compared to 0.7651 (FEDMETA) and 0.7482 (FEDAVG).\n\n3. **Impact of Period Drift**:\n   - Visualizations of label distributions across clients and rounds highlight the increasing diversity in data distribution, indicating both client drift and period drift.\n   - FEDPA achieves faster and more stable convergence compared to other methods, even when client drift is eliminated (data shuffled to be iid).\n\n4. **Comparison of Proxy Dataset Usage**:\n   - FEDPA, FEDDF, and FEDMETA all use proxy datasets but differ in approach. FEDPA's method of learning an aggregative bias is safer and more effective in handling period drift compared to direct parameter updates (FEDMETA) or ensemble distillation (FEDDF).\n\n---\n\n### Advantages of FEDPA\n\n- **Robustness to Non-iidness**: FEDPA consistently outperforms baseline methods, showing minimal performance degradation as non-iidness increases.\n- **Faster Convergence**: The meta-learning-based aggregator ensures faster and more stable convergence, even in scenarios with high non-iidness or period drift.\n- **Task Flexibility**: FEDPA provides a flexible framework tailored to specific tasks and datasets, leveraging proxy datasets to adapt to non-iidness.\n\n---\n\n### Privacy Considerations\n\nWhile proxy datasets can enhance FL performance, their use may raise privacy concerns in sensitive domains like healthcare. However, in permissible scenarios (e.g., natural image recognition), proxy datasets can significantly improve FL performance.\n\n---\n\n### Conclusion\n\nThe study identifies *period drift* as a key factor degrading FL convergence and proposes FEDPA as a novel aggregation strategy to address both period drift and client drift. By leveraging a meta-learning-based aggregator trained on a proxy dataset, FEDPA achieves superior performance, faster convergence, and robustness to non-iidness compared to state-of-the-art methods. The approach is validated through extensive experiments on FEMNIST and MovieLens 1M datasets, highlighting its potential to improve FL performance in real-world, cross-device settings.",
  "ref": {
    "weaknesses": [
      "Lack of clarity in the presentation of methods and results.",
      "Insufficient theoretical grounding or explanation of methodology.",
      "Underdeveloped or inadequately justified methodological choices.",
      "Limited or non-comprehensive empirical evaluation.",
      "Vague or unclear descriptions of key concepts and algorithms."
    ],
    "improvements": [
      "Enhance clarity and structure of the exposition to improve readability.",
      "Provide detailed theoretical analysis to support methodological claims.",
      "Justify methodological choices with fine-grained evaluation and comparison.",
      "Expand empirical validation to convincingly demonstrate the effectiveness of the approach.",
      "Ensure clear and precise definitions of all terms and algorithms used."
    ]
  },
  "rev": "**1. Summary**  \nThe paper introduces FEDPA, a novel meta-learning-based aggregation strategy for federated learning (FL) that addresses the challenges of client drift and period drift in non-iid data settings. FEDPA employs a parameterized aggregator trained on a proxy dataset to adaptively mitigate aggregation bias, enhancing convergence and performance in FL. The approach is validated through experiments on FEMNIST and MovieLens 1M datasets, demonstrating superior performance over baseline methods like FEDAVG and FEDPROX, particularly in scenarios with high non-iidness.\n\n**2. Strengths**  \n- The paper addresses a significant challenge in federated learning, namely the dual issues of client drift and period drift, which are crucial for improving model convergence and performance in non-iid settings.\n- The introduction of a meta-learning-based parameterized aggregator is innovative, providing a dynamic and adaptive approach to aggregation that outperforms traditional static methods.\n- The empirical results are robust, showcasing the effectiveness of FEDPA across different datasets and metrics, with clear improvements over existing baseline methods.\n- The use of a proxy dataset for training the aggregator is a practical approach that balances computational efficiency with performance gains.\n\n**3. Weaknesses**  \n- **Clarity of Methodology**: The explanation of the meta-learning framework and its integration into the aggregation process is somewhat dense and could benefit from clearer exposition. Specifically, Section 3.2 could include more intuitive explanations or visual aids to enhance understanding. Consider adding a flowchart or diagram to illustrate the meta-learning process.\n- **Theoretical Justification**: While the empirical results are strong, the paper lacks a rigorous theoretical analysis of why the meta-learning-based approach effectively mitigates period drift. A more detailed theoretical discussion in Section 3.1 would strengthen the paper's claims. Consider including theoretical insights or proofs to support the observed empirical phenomena.\n- **Baseline Comparisons**: The choice of baselines, while comprehensive, could be expanded to include more recent methods that address similar challenges, such as personalized federated learning approaches. In Section 4.1, consider adding comparisons with newer methods to provide a broader context for FEDPA's performance.\n- **Proxy Dataset Details**: The selection and role of the proxy dataset are crucial to FEDPA's success, yet the paper provides limited discussion on how the proxy dataset is chosen and its potential impact on privacy. Section 3.3 could benefit from a more detailed explanation of the proxy dataset's selection criteria and its implications.\n- **Figure Clarity**: Some figures, such as Figure 3, have captions that are not sufficiently descriptive, and the visual elements could be clearer. Ensure that all figures are self-contained with comprehensive captions and that the visual elements are easily interpretable.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**: The paper is generally well-organized, with a logical flow from problem identification to solution and results. However, some sections, particularly those detailing the methodology, could benefit from clearer explanations and additional context to aid comprehension. Definitions and assumptions should be explicitly stated to avoid ambiguity.\n\n  **(b) Figure & Caption Clarity**: While the figures are generally informative, some captions lack detail, and the figures themselves could be made clearer. For instance, Figure 3 should have a more descriptive caption explaining the axes and the significance of the visualized data. Ensure that all figures are fully self-explanatory and that their relevance to the text is clear.\n\n  **(c) Reproducibility Transparency**: The paper provides a good level of detail regarding experimental setups, including datasets, hyperparameters, and baseline methods. However, it lacks explicit mention of code availability, which is crucial for reproducibility. Including a link to the code repository or detailed pseudocode would enhance reproducibility. Additionally, more information on the random seeds and hardware used would be beneficial.\n\n**5. Novelty & Significance**  \nThe paper presents a novel approach to addressing a well-known problem in federated learning, namely the challenges posed by non-iid data distributions. The use of a meta-learning-based aggregator is a significant contribution, offering a dynamic and adaptive solution that outperforms traditional methods. The work is well-motivated and contextualized within the existing literature, and the empirical results substantiate the claims made. The significance of the work lies in its potential to improve FL performance in real-world applications, particularly in cross-device settings where data heterogeneity is prevalent. Overall, the paper contributes valuable insights and methodologies to the field of federated learning, with implications for both theoretical advancements and practical implementations.",
  "todo": [
    "Revise methodology explanation: Simplify and clarify the meta-learning framework and its integration into the aggregation process [Section 3.2]",
    "Add visual aid: Include a flowchart or diagram to illustrate the meta-learning process [Section 3.2]",
    "Expand theoretical justification: Provide a detailed theoretical discussion or proofs on why the meta-learning-based approach mitigates period drift [Section 3.1]",
    "Update baseline comparisons: Include comparisons with more recent personalized federated learning methods [Section 4.1]",
    "Detail proxy dataset selection: Explain the criteria for choosing the proxy dataset and discuss its privacy implications [Section 3.3]",
    "Enhance figure clarity: Ensure all figures, especially Figure 3, have comprehensive captions and clear visual elements [Page 6, Figure 3]",
    "Improve textual clarity: Provide clearer explanations and additional context for the methodology, explicitly stating definitions and assumptions [Throughout the paper]",
    "Ensure figure and caption clarity: Make all figures self-contained and relevant to the text [Throughout the paper]",
    "Enhance reproducibility: Include a link to the code repository or detailed pseudocode, and provide information on random seeds and hardware used [Section 4]"
  ],
  "timestamp": "2025-10-30T15:00:17.710115",
  "manuscript_file": "manuscript.pdf",
  "image_file": "concat_image.png"
}