{
  "title": "Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data",
  "abstract": "The implicit biases of gradient-based optimization algorithms are conjectured to\nbe a major factor in the success of modern deep learning. In this work, we inves-\ntigate the implicit bias of gradient flow and gradient descent in two-layer fully-\nconnected neural networks with leaky ReLU activations when the training data\nare nearly-orthogonal, a common property of high-dimensional data. For gradi-\nent flow, we leverage recent work on the implicit bias for homogeneous neural\nnetworks to show that asymptotically, gradient flow produces a neural network\nwith rank at most two. Moreover, this network is an ℓ2-max-margin solution\n(in parameter space), and has a linear decision boundary that corresponds to an\napproximate-max-margin linear predictor. For gradient descent, provided the ran-\ndom initialization variance is small enough, we show that a single step of gradient\ndescent suffices to drastically reduce the rank of the network, and that the rank\nremains small throughout training. We provide experiments which suggest that a\nsmall initialization scale is important for finding low-rank neural networks with\ngradient descent.\n1 I NTRODUCTION",
  "summary": "### Structured Overview of the Paper\n\nThis paper, presented at ICLR 2023, investigates the **implicit bias** of gradient-based optimization methods, particularly **gradient flow** (continuous-time gradient descent) and **gradient descent** (discrete steps), in training two-layer fully-connected neural networks with **leaky ReLU activations**. The study focuses on high-dimensional, nearly-orthogonal data and explores the role of initialization scale, learning rates, and data geometry in shaping the training dynamics and generalization properties of these networks.\n\n---\n\n### Key Contributions and Findings\n\n#### 1. **Gradient Flow Dynamics**\n- **Rank Reduction**: Gradient flow asymptotically produces a weight matrix \\( W \\) with **rank at most 2**.\n- **Margin Maximization**: The resulting network is an **ℓ2-max-margin solution** in parameter space, with a **linear decision boundary**. While this boundary does not guarantee the exact ℓ2-max-margin, it approximately maximizes the margin.\n- **Theoretical Framework**: The analysis builds on prior work on homogeneous networks, showing that gradient flow converges to solutions satisfying the **Karush–Kuhn–Tucker (KKT) conditions** for margin maximization.\n\n#### 2. **Gradient Descent Dynamics**\n- **Stable Rank Reduction**: With small initialization variance, a **single step** of gradient descent significantly reduces the rank of the weight matrix \\( W \\), and the rank remains small throughout training.\n- **Stable Rank Behavior**: The stable rank (\\( \\|W\\|_F^2 / \\|W\\|_2^2 \\)) drops from \\( \\text{min}(m, d) \\) (where \\( m \\) is the number of neurons and \\( d \\) is the input dimension) to a constant value independent of \\( m \\), \\( d \\), or the number of samples.\n- **Initialization Scale**: Small initialization variance is critical for finding low-rank solutions, as confirmed by both theoretical analysis and experiments.\n\n#### 3. **Theoretical Insights**\n- **Convergence Properties**:\n  - Gradient flow converges to zero loss and aligns with a weight matrix \\( W \\) satisfying the KKT conditions.\n  - Gradient descent minimizes the empirical risk efficiently under specific conditions on step size and initialization scale.\n- **Data Geometry**:\n  - High-dimensional, nearly-orthogonal data ensures that the learned solutions exhibit low-rank properties and linear decision boundaries.\n  - Near-orthogonality of data is critical for the theoretical guarantees, as it ensures gradient persistence and near-orthogonality during training.\n\n#### 4. **Experimental Validation**\n- **Binary Classification Tasks**:\n  - Experiments on high-dimensional binary cluster data validated the theoretical predictions about rank reduction and stable rank behavior.\n  - Smaller initialization scales led to faster and more pronounced rank reduction.\n- **CIFAR-10 Dataset**:\n  - For non-high-dimensional data, the initialization scale significantly influenced the stable rank:\n    - Default TensorFlow initialization resulted in a stable rank above 74.\n    - Smaller initialization variance reduced the stable rank to as low as 3.25, with rank increasing only when the network began to overfit.\n- **2-XOR Data**:\n  - For the 2-XOR distribution, leaky ReLU networks with large leaky parameters (\\( \\gamma \\)) and high input dimensions (\\( d \\)) failed to generalize, producing linear decision boundaries with 50% test accuracy, as predicted by the theory.\n\n---\n\n### Context and Related Work\n\n#### Implicit Bias in Neural Networks\n- **Margin Maximization**:\n  - Previous studies (e.g., Lyu & Li, 2019; Ji & Telgarsky, 2020) showed that homogeneous networks trained with classification losses converge to KKT points of the maximum-margin problem.\n  - This work extends these results to nearly-orthogonal data, showing that gradient flow may converge to a linear classifier that approximately maximizes the margin.\n- **Rank Minimization**:\n  - Ji & Telgarsky (2018, 2020) demonstrated that gradient flow in linear networks converges to rank-1 weight matrices.\n  - This study generalizes these findings to leaky ReLU networks, showing that gradient descent and gradient flow bias the network toward low-rank solutions.\n\n#### Training Dynamics\n- **Linearly Separable Data**:\n  - Prior work (e.g., Brutzkus et al., 2017; Frei et al., 2021) analyzed the dynamics of gradient descent and stochastic gradient descent (SGD) on linearly separable data, showing that these methods achieve zero loss and generalize well.\n- **Non-Linearly Separable Data**:\n  - Studies like Cao et al. (2022) and Frei et al. (2022) explored the impact of data geometry and signal-to-noise ratio on overfitting and generalization in high-dimensional settings.\n- **Orthogonal Inputs**:\n  - Boursier et al. (2022) analyzed gradient flow dynamics on squared loss for two-layer ReLU networks with orthogonal inputs, providing insights into the role of data geometry.\n\n---\n\n### Theoretical Analysis of Implicit Bias\n\n#### 1. **Homogeneous Networks**\n- Gradient flow in homogeneous networks (e.g., ReLU or leaky ReLU) minimizes a maximum-margin problem in parameter space, with weights growing unbounded as the loss approaches zero.\n\n#### 2. **Depth-2 Leaky ReLU Networks**\n- For depth-2 leaky ReLU networks, the implicit bias aligns with minimizing the Frobenius norm of the weight matrix, subject to margin constraints. The problem is non-smooth, requiring Clarke subdifferentials for analysis.\n\n#### 3. **Key Theorems**\n- **Theorem 3.2**:\n  - Gradient flow produces networks with linear decision boundaries, achieving perfect classification and low-rank weight matrices.\n  - The decision boundary approximately maximizes the margin, with a bound on the deviation from the optimal \\( \\ell_2 \\)-max-margin predictor.\n- **Theorem 4.2**:\n  - Gradient descent with small initialization variance and appropriate step size drives the empirical risk to zero while maintaining a bounded stable rank.\n\n---\n\n### Practical Implications\n\n1. **Initialization Scale**:\n   - Smaller initialization scales enable faster convergence to low-rank solutions, which can enhance generalization in some cases but may limit performance in others requiring complex decision boundaries.\n\n2. **Data Geometry**:\n   - High-dimensional, nearly-orthogonal data ensures that gradient-based optimization methods exhibit beneficial implicit biases, such as rank reduction and margin maximization.\n\n3. **Generalization and Overfitting**:\n   - While low-rank solutions often generalize well, they may fail for data distributions requiring non-linear decision boundaries (e.g., 2-XOR).\n\n---\n\n### Conclusion\n\nThis paper provides a comprehensive theoretical and empirical analysis of the implicit bias of gradient-based optimization methods in training two-layer leaky ReLU networks. It highlights the critical role of initialization scale, data geometry, and optimization dynamics in shaping the learned solutions. The findings have significant implications for understanding and designing neural network training strategies, particularly in high-dimensional settings.",
  "ref": {
    "weaknesses": [
      "Lack of clarity in theoretical statements and proofs, leading to potential misinterpretations or inaccuracies.",
      "Insufficient comparison with prior work, particularly when the scope or assumptions differ significantly.",
      "Overlooking alternative methodologies or techniques that could provide tighter or more robust results.",
      "Failure to adequately justify assumptions or provide examples to validate their applicability.",
      "Inadequate discussion of the limitations or generalizability of the proposed methods or results."
    ],
    "improvements": [
      "Ensure clarity and rigor in theoretical statements and proofs, avoiding logical gaps or unsupported claims.",
      "Provide comprehensive comparisons with related work, explicitly addressing differences in scope, assumptions, and methodologies.",
      "Explore alternative techniques or approaches to strengthen theoretical results or bounds.",
      "Include examples or scenarios to validate assumptions and demonstrate their practical relevance.",
      "Discuss the generalizability and potential limitations of the proposed methods to provide a balanced perspective."
    ]
  },
  "rev": "**1. Summary**  \nThe paper investigates the implicit bias of gradient-based optimization methods, specifically gradient flow and gradient descent, in training two-layer fully-connected neural networks with leaky ReLU activations. It focuses on high-dimensional, nearly-orthogonal data and examines the effects of initialization scale, learning rates, and data geometry on training dynamics and generalization. Key findings include the rank reduction of weight matrices, margin maximization, and the critical role of initialization scale in achieving low-rank solutions. Theoretical insights are supported by experiments on binary classification tasks and datasets like CIFAR-10, demonstrating the practical implications of the theoretical results.\n\n**2. Strengths**  \n- The paper provides a comprehensive theoretical framework that extends previous work on homogeneous networks to leaky ReLU networks, offering new insights into the implicit bias of gradient-based methods.\n- The experimental validation is robust, covering a range of datasets and scenarios that effectively demonstrate the theoretical predictions.\n- The study addresses a significant gap in understanding the role of initialization scale and data geometry in training dynamics, contributing valuable knowledge to the field.\n\n**3. Weaknesses**  \n- **Clarity in Theoretical Statements**: Some theoretical statements, particularly in Section 3.2, lack clarity and could lead to misinterpretation. It is recommended to enhance the rigor and detail of these statements to avoid logical gaps.\n- **Comparison with Prior Work**: The paper does not sufficiently compare its findings with related work, especially in Section 4.2. Including a detailed comparison with similar studies would strengthen the contextualization of the results.\n- **Assumption Justification**: The assumptions regarding data geometry, such as near-orthogonality, are not adequately justified in Section 2.1. Providing examples or scenarios that validate these assumptions would enhance their practical relevance.\n- **Limitations Discussion**: The paper lacks a thorough discussion of the limitations and generalizability of the proposed methods, particularly in Section 5. Including such a discussion would provide a more balanced perspective on the findings.\n- **Figure Caption Clarity**: The caption for Figure 3 is ambiguous and does not clearly explain the significance of the depicted results. Clarifying the caption would improve the reader's understanding of the figure's relevance.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**: The paper is generally well-written, with a logical flow of ideas. However, some sections, particularly those involving complex theoretical concepts, could benefit from additional explanations to enhance clarity. Mathematical notations are well-defined, but assumptions could be more explicitly stated.\n  \n  **(b) Figure & Caption Clarity**: Figures are generally effective in illustrating the main claims, but some captions, such as that of Figure 3, lack clarity. Ensuring that captions are self-sufficient and comprehensible would enhance the overall presentation.\n  \n  **(c) Reproducibility Transparency**: The paper provides adequate detail on experimental setups, including datasets and initialization scales. However, it lacks specific information on hyperparameters, hardware, and random seeds, which are crucial for reproducibility. Mentioning code availability would also be beneficial.\n\n**5. Novelty & Significance**  \nThe paper addresses the important problem of understanding the implicit bias of gradient-based optimization methods in neural network training. The approach is well-motivated and contextualized within the existing literature, extending previous findings to leaky ReLU networks and high-dimensional data. The theoretical and empirical results are scientifically rigorous, offering new insights into the role of initialization scale and data geometry. The work is significant as it contributes to the broader understanding of neural network training dynamics, with potential implications for designing more effective training strategies. While the paper does not achieve state-of-the-art results, it provides valuable theoretical and practical insights that are relevant to the ICLR community.",
  "todo": [
    "Revise theoretical statements: Enhance clarity and rigor to avoid misinterpretation [Section 3.2]",
    "Add comparison with related work: Strengthen contextualization of results [Section 4.2]",
    "Justify assumptions: Provide examples or scenarios validating data geometry assumptions [Section 2.1]",
    "Discuss limitations: Include a thorough discussion of limitations and generalizability [Section 5]",
    "Clarify Figure 3 caption: Explain the significance of the depicted results [Page 5, Figure 3]",
    "Enhance textual clarity: Add explanations for complex theoretical concepts [Throughout the paper]",
    "Improve reproducibility: Include specific information on hyperparameters, hardware, and random seeds [Experimental Setup Section]",
    "Mention code availability: Ensure transparency and facilitate reproducibility [Conclusion or Appendix]"
  ],
  "timestamp": "2025-10-30T13:43:23.684470",
  "manuscript_file": "manuscript.pdf",
  "image_file": "concat_image.png"
}