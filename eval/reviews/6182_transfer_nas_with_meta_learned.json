{
    "paper_id": "6182_transfer_nas_with_meta_learned",
    "title": "Transfer NAS with Meta-learned Bayesian Surrogates",
    "abstract": "While neural architecture search (NAS) is an intensely-researched area, approaches typically still suffer from either (i) high computational costs or (ii) lack of robustness across datasets and experiments. Furthermore, most methods start searching for an optimal architecture from scratch, ignoring prior knowledge. This is in contrast to the manual design process by researchers and engineers that leverage previous deep learning experiences by, e.g., transferring architectures from previously solved, related problems. We propose to adopt this human design strategy and introduce a novel surrogate for NAS, that is meta-learned across prior architecture evaluations across different datasets. We utilizes Bayesian Optimization (BO) with deep-kernel Gaussian Processes, graph neural networks for the architecture embeddings and a transformer-based set encoder of datasets. As a result, our method consistently achieves state-of-the-art results on six computer vision datasets, while being as fast as one-shot NAS methods.",
    "human_review": "Summary Of The Paper:\nThis work proposes a transferrable surrogate for NAS based on Bayesian Optimization with deep-kernel Gaussian Processes. The proposed predictor can be adapt to unseen datasets rapidly by significantly reducing the search cost of NAS. On the NAS-Bench-201 and multiple unseen datasets, this work outperformed recent NAS methods including MetaD2A for the performance of the obtained architecture and search efficiency.\n\nStrength And Weaknesses:\nStrengths\n\nI think this work well addressed the main limitation of MetaD2A which is the meta-learning-based transferrable NAS method. As this paper said, the meta-learning-based predictor proposed by MetaD2A can be exploited to unseen datasets after once meta-training, which significantly reduces the search time for unseen datasets. However, MetaD2A only exploits the meta-learned predictor, can not adapt to the unseen dataset even if the unseen task provides few-shot samples. This work combines the BO method to tackle the problem of transferrable predictors by allowing them to reflect feedback from unseen tasks.\n\nWeaknesses\n\nI think while the contribution of this work in the structure of predictor is limited, this work assigned the part of the paper for them too much. For example, using both transformer-based set encoder and graph encoder together is almost same with MetaD2A, this paper described it as the figure and performed ablation study about that. I think it would be better to emphasis the difference between MetaD2A and this work or BO + predictor as a Figure.\n\nClarity, Quality, Novelty And Reproducibility:\nI think clarity of this paper is needed to be improved as there are mixing between their contributions and previous works' contributions. Actually, applying BO to NAS is not new, yet, to my knowledge, this work is the first to use BO for meta-learning-based predictor for NAS and addresses the important problem in meta-learning-based NAS. On the NAS-Bench-201 benchmark and multiple unseen datasets, their experiments are solid to support this work. Thus, i think the overall quality is good, yet, one caveat is that NAS-Bench-201 is rather small and narrow benchmark.\n\nSummary Of The Review:\nThe good points are that this work successfully addressed the important problem of the meta-learning-based prediction model in NAS with solid experiments. The bad points are that BO is not new in NAS domain, the composition of the paper is needed to be improved, and the benchmark that they used is small.\n\nCorrectness: 3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\nTechnical Novelty And Significance: 4: The contributions are significant, and do not exist in prior works.\nEmpirical Novelty And Significance: 2: The contributions are only marginally significant or novel.\nFlag For Ethics Review: NO.\nRecommendation: 8: accept, good paper\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
    "text_summary": "### Motivation\nNeural Architecture Search (NAS) has shifted the focus in deep learning from manual feature engineering to automated architecture design. However, traditional NAS methods, such as reinforcement learning, evolutionary algorithms, and Bayesian optimization, are computationally expensive, while faster alternatives like one-shot methods often lack robustness. Zero-cost proxies, though efficient, provide limited performance insights. A promising but underexplored direction is leveraging prior knowledge across datasets, as human designers often reuse architectures from related tasks. Existing transfer-based NAS methods are constrained by small datasets, limited search spaces, or poor adaptability to new data. This paper addresses these challenges by introducing a novel NAS approach that combines transfer learning and Bayesian optimization (BO) to improve efficiency and robustness.\n\n### Method\nThe proposed method, **TNAS (Transferable Neural Architecture Search)**, treats NAS as a transfer learning problem, leveraging prior evaluations of architectures across datasets. TNAS employs a Bayesian Optimization framework with a **deep Gaussian Process (GP) surrogate model** that integrates architecture and dataset encodings. Key components include:\n\n1. **Architecture Encoding**: Neural architectures are represented as directed acyclic graphs (DAGs) and encoded using a **Graph Neural Network (GNN)**. The GNN traverses the graph in forward and backward directions using GRU cells, followed by a fully connected layer to produce vector representations.\n   \n2. **Dataset Encoding**: Datasets are encoded using a **transformer-based model** that captures dataset-specific meta-features. Two stacked Set-Transformer layers are used: one for intra-class interactions and another for inter-class interactions.\n\n3. **Deep Kernel Learning**: The architecture and dataset encodings are fused through a fully connected neural network to define a **deep kernel** for the GP surrogate. This kernel measures the similarity between architecture-dataset pairs, considering both structural features and dataset-specific performance.\n\n4. **Meta-Learning**: The parameters of the GNN, transformer, and kernel are meta-learned by maximizing the log marginal likelihood of the GP surrogate. The REPTILE algorithm is used for efficient parameter updates.\n\n5. **Bayesian Optimization**: During meta-testing, the learned kernel is used in a GP for BO. The method balances exploration and exploitation using an acquisition function (e.g., Expected Improvement) and adapts to new tasks by updating the surrogate model with new evaluations.\n\n### Experiments\nTNAS was evaluated on six computer vision datasets: CIFAR-10, CIFAR-100, SVHN, Aircraft, Oxford IIT Pets, and MNIST. The experiments used two search spaces:\n- **NAS-Bench-201**: A tabular benchmark for CIFAR-10 and CIFAR-100.\n- **MobileNetV3**: A larger search space for real-world applications.\n\n#### Baselines\nTNAS was compared against state-of-the-art NAS methods, including:\n1. **Random Search (RS)**: Uniform sampling of architectures.\n2. **Bayesian Optimization (BO)**: GP surrogate with Matérn kernel.\n3. **HEBO**: A black-box HPO method with input/output warping.\n4. **BANANAS**: A BO method using neural network ensembles.\n5. **NASBOWL**: A GP-based BO method with Weisfeiler-Lehman kernels.\n6. **MetaD2A**: A transfer-based NAS method that generates and ranks architectures using task-specific meta-features.\n\n#### Results\nTNAS consistently outperformed baselines across all datasets in terms of accuracy and efficiency:\n- **CIFAR-10**: Achieved 94.37% accuracy, matching MetaD2A but with faster convergence.\n- **CIFAR-100**: Demonstrated significant improvements in accuracy and GPU efficiency.\n- **MNIST, Aircraft, Pets, and SVHN**: Identified better architectures within fewer GPU hours compared to baselines.\n\n#### Ablation Studies\n1. **Component Analysis**: Removing the GNN or transformer-based dataset encoder degraded performance, confirming their importance.\n2. **Initialization and Meta-Learning**: Using top-performing architectures from meta-training datasets as initialization improved results. Meta-learning the surrogate model further enhanced performance.\n\n### Contributions\n1. **Transfer Learning for NAS**: TNAS reframes NAS as a transfer learning problem, leveraging prior evaluations to improve efficiency and robustness.\n2. **Deep Kernel GP Surrogate**: Combines GNN-based architecture encoding, transformer-based dataset encoding, and a deep kernel GP surrogate for effective modeling of architecture-dataset relationships.\n3. **Adaptability**: Unlike MetaD2A, TNAS adapts to new tasks during meta-testing by updating the surrogate model, ensuring better performance on diverse datasets.\n4. **State-of-the-Art Performance**: TNAS achieves superior accuracy and efficiency across multiple benchmarks, outperforming both black-box and one-shot NAS methods.\n\n### Conclusion\nTNAS introduces a novel, efficient, and robust NAS method that integrates meta-learned Bayesian surrogates with transfer learning. By combining architecture and dataset encodings into a deep kernel GP surrogate, TNAS bridges the gap between black-box optimization and one-shot methods. It achieves state-of-the-art performance across diverse datasets with lower computational costs. The method adheres to NAS best practices, ensuring reproducibility and fairness in comparisons. Future work could explore extending the surrogate model to capture interactions between architectures and hyperparameters, further enhancing its transferability and scalability.\n\nThe code and experimental protocols are publicly available, providing a foundation for future research in transfer-based NAS.",
    "text_only_review": "#### 1. Summary\nThe paper introduces **TNAS (Transferable Neural Architecture Search)**, a novel approach to Neural Architecture Search (NAS) that leverages transfer learning and Bayesian Optimization (BO) to improve efficiency and robustness. TNAS utilizes prior evaluations of architectures across datasets and employs a deep Gaussian Process (GP) surrogate model with architecture and dataset encodings. The architecture encoding is based on Graph Neural Networks (GNNs), while dataset encoding uses a transformer-based model. The method integrates these encodings through a deep kernel for the GP surrogate, which is meta-learned to maximize log marginal likelihood. TNAS is evaluated on six computer vision datasets and demonstrates superior performance in terms of accuracy and efficiency compared to state-of-the-art NAS methods. The paper also includes ablation studies to validate the importance of its components and highlights the adaptability of TNAS to new tasks.\n\n---\n\n#### 2. Strengths\n1. **Innovative Methodology**: The paper introduces a novel combination of transfer learning and Bayesian Optimization for NAS, addressing limitations of prior methods such as computational inefficiency and poor adaptability.\n2. **Deep Kernel Learning**: The use of a deep kernel GP surrogate that integrates GNN-based architecture encoding and transformer-based dataset encoding is a strong contribution, enabling effective modeling of architecture-dataset relationships.\n3. **Meta-Learning**: The meta-learning approach for optimizing the surrogate model parameters is well-motivated and enhances the adaptability of TNAS to new datasets.\n4. **Comprehensive Evaluation**: The experiments are conducted on diverse datasets and search spaces, demonstrating the generalizability of TNAS. The inclusion of multiple baselines ensures a fair comparison.\n5. **State-of-the-Art Results**: TNAS achieves superior accuracy and efficiency across benchmarks, outperforming both black-box and transfer-based NAS methods.\n6. **Ablation Studies**: The ablation studies provide valuable insights into the contributions of individual components, such as the GNN and transformer-based encoders.\n7. **Reproducibility**: The authors adhere to NAS best practices and provide code and experimental protocols, ensuring reproducibility and transparency.\n\n---\n\n#### 3. Weaknesses\n1. **Limited Discussion on Computational Overhead**: While TNAS is presented as efficient, the paper does not provide a detailed analysis of the computational overhead introduced by the GNN and transformer-based encodings, especially during meta-training.\n2. **Scalability to Larger Search Spaces**: Although TNAS is evaluated on NAS-Bench-201 and MobileNetV3 search spaces, the scalability of the method to significantly larger or more complex search spaces (e.g., DARTS or ENAS) is not explored.\n3. **Dataset Encoding Generality**: The transformer-based dataset encoding is tailored to computer vision tasks. The adaptability of this encoding to other domains (e.g., natural language processing or reinforcement learning) is not discussed.\n4. **Limited Exploration of Acquisition Functions**: The paper primarily focuses on Expected Improvement as the acquisition function. Exploring alternative acquisition functions could provide insights into the robustness of the BO framework.\n5. **Meta-Learning Efficiency**: The use of the REPTILE algorithm for meta-learning is briefly mentioned but not thoroughly analyzed. A comparison with alternative meta-learning algorithms (e.g., MAML) could strengthen the claims of efficiency.\n6. **Transferability Across Domains**: While TNAS demonstrates strong performance on computer vision datasets, its transferability to entirely different domains (e.g., NLP or time-series) is not evaluated, limiting its broader applicability.\n\n---\n\n#### 4. Clarity & Reproducibility\n- **Clarity**: The paper is well-written and clearly structured, with detailed explanations of the methodology, experiments, and results. The use of diagrams or visualizations to illustrate the architecture and dataset encodings would further enhance clarity.\n- **Reproducibility**: The authors provide code and experimental protocols, which is commendable. However, the paper lacks detailed hyperparameter settings for the GNN, transformer, and GP surrogate, which may hinder exact reproduction of results.\n\n---\n\n#### 5. Novelty & Significance\n- **Novelty**: The integration of transfer learning, deep kernel learning, and Bayesian Optimization in the context of NAS is a novel and significant contribution. The use of GNNs for architecture encoding and transformers for dataset encoding is innovative and well-justified.\n- **Significance**: TNAS addresses key challenges in NAS, such as computational inefficiency and poor adaptability, making it a valuable contribution to the field. Its superior performance across diverse datasets highlights its potential impact on real-world applications.\n\n---\n\n#### Overall Recommendation\nThe paper presents a significant advancement in NAS by introducing a novel transfer-based approach that combines meta-learned Bayesian surrogates with deep kernel learning. Despite some limitations, such as the lack of scalability analysis and limited exploration of alternative domains, the strengths of the paper outweigh its weaknesses. The methodology is innovative, the experiments are comprehensive, and the results are compelling. I recommend **acceptance** at a top-tier conference, with minor revisions to address the identified weaknesses.",
    "merged_image_path": "temp_cache\\6182_transfer_nas_with_meta_learned_merged.png",
    "image_only_review": "#### 1. Summary\nThe paper presents a novel approach for Transfer Neural Architecture Search (NAS) using Meta-Learned Bayesian Surrogates. The authors propose a method that leverages meta-learning to enhance the efficiency of NAS by transferring knowledge from previously solved tasks to new tasks. The approach involves using a Gaussian Process (GP) surrogate model that is meta-learned to predict the performance of neural architectures across different tasks. The paper evaluates the proposed method on several benchmark datasets and compares its performance to existing state-of-the-art NAS methods, demonstrating improvements in both efficiency and accuracy.\n\n#### 2. Strengths\n- **Innovative Approach**: The integration of meta-learning with Bayesian optimization for NAS is a novel contribution that addresses the challenge of efficiently transferring knowledge across tasks.\n- **Comprehensive Evaluation**: The authors conduct extensive experiments on multiple benchmark datasets, providing a thorough comparison with existing NAS methods.\n- **Performance Gains**: The proposed method shows significant improvements in both search efficiency and model performance compared to state-of-the-art NAS techniques.\n- **Theoretical Foundation**: The use of Gaussian Processes and the meta-learning framework is well-grounded in theory, providing a solid foundation for the proposed method.\n\n#### 3. Weaknesses\n- **Complexity**: The proposed method introduces additional complexity due to the integration of meta-learning and Bayesian optimization, which may limit its accessibility and applicability in practical scenarios.\n- **Limited Task Diversity**: While the paper evaluates the method on several datasets, the diversity of tasks could be expanded to further validate the generalizability of the approach.\n- **Scalability Concerns**: The scalability of the approach to very large-scale datasets or tasks with significantly different characteristics from the training tasks is not thoroughly addressed.\n\n#### 4. Clarity & Reproducibility\n- **Clarity**: The paper is generally well-written and structured, with clear explanations of the proposed method and its components. However, some sections, particularly those involving mathematical formulations, could benefit from additional clarification for readers less familiar with Gaussian Processes or meta-learning.\n- **Reproducibility**: The authors provide sufficient details about the experimental setup, including hyperparameters and datasets used, which supports reproducibility. However, the paper would benefit from the inclusion of code or pseudocode for the proposed algorithm to further facilitate replication of results.\n\n#### 5. Novelty & Significance\n- **Novelty**: The combination of meta-learning with Bayesian optimization in the context of NAS is a novel contribution that advances the state-of-the-art in this area. The approach is innovative in its use of a meta-learned surrogate model to enhance transferability across tasks.\n- **Significance**: The proposed method has the potential to significantly impact the field of NAS by reducing the computational cost and time required to find optimal architectures, particularly in scenarios where multiple related tasks are involved. This can lead to more efficient deployment of NAS in real-world applications where computational resources are limited.",
    "multimodal_review": "**1. Summary**  \nThe paper introduces TNAS (Transferable Neural Architecture Search), a novel approach to Neural Architecture Search (NAS) that leverages transfer learning and Bayesian optimization to enhance efficiency and robustness. TNAS treats NAS as a transfer learning problem, utilizing a deep Gaussian Process (GP) surrogate model that combines architecture and dataset encodings. The method employs a Graph Neural Network (GNN) for architecture encoding and a transformer-based model for dataset encoding, integrating these through a deep kernel for the GP surrogate. Experiments across six computer vision datasets demonstrate TNAS's superior performance in accuracy and efficiency compared to state-of-the-art NAS methods.\n\n**2. Strengths**  \n- The integration of transfer learning with NAS is a novel approach that effectively leverages prior knowledge to improve search efficiency and robustness.\n- The use of a deep Gaussian Process surrogate model with architecture and dataset encodings is innovative and provides a sophisticated mechanism for modeling architecture-dataset relationships.\n- TNAS demonstrates significant improvements in accuracy and efficiency across multiple datasets, showcasing its adaptability and effectiveness.\n- The paper provides a comprehensive experimental evaluation, including comparisons with several baseline methods and detailed ablation studies to validate the importance of its components.\n- The authors have made their code and experimental protocols publicly available, promoting transparency and reproducibility.\n\n**3. Weaknesses**  \n- **Theory and Justification**: The theoretical justification for the choice of the REPTILE algorithm in meta-learning is not thoroughly discussed. It would be beneficial to include a rationale for this choice in Section 3.4, potentially comparing it with other meta-learning algorithms.\n- **Clarity**: The explanation of the deep kernel learning process in Section 3.3 is somewhat dense and could benefit from additional clarification or illustrative examples to aid understanding.\n- **Baseline Comparison**: While the paper compares TNAS with several NAS methods, it lacks a direct comparison with more recent transfer-based NAS methods beyond MetaD2A. Including such comparisons in Section 4.1 would strengthen the evaluation.\n- **Figure Clarity**: Figure 2's caption does not adequately explain the significance of the plotted curves and their relation to the paper's claims. Enhancing the caption to provide more context would improve comprehension.\n- **Reproducibility Details**: The paper does not specify the random seeds used in experiments, which is crucial for reproducibility. Including this information in Section 4.2 would enhance transparency.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**  \n  The paper is generally well-written, with clear explanations of the main ideas and methods. However, certain sections, such as the deep kernel learning process, could benefit from additional clarification. The section titles are informative, and mathematical notations are well-defined. Limitations and assumptions are briefly mentioned but could be more explicitly articulated.\n\n  **(b) Figure & Caption Clarity**  \n  Figures are generally effective in illustrating the main claims, but some captions, such as that of Figure 2, lack sufficient detail to be fully comprehensible on their own. Axes, labels, and legends are consistent and readable, and diagrams correlate well with the textual descriptions.\n\n  **(c) Reproducibility Transparency**  \n  The paper provides a good level of detail regarding experimental setups, including datasets and search spaces. However, it lacks specific information on hyperparameters, hardware, training time, and random seeds. While code availability is mentioned, the inclusion of ablation studies is commendable, though further detail on algorithmic steps would be beneficial.\n\n**5. Novelty & Significance**  \nThe paper addresses a significant problem in NAS by introducing a novel approach that combines transfer learning with Bayesian optimization, offering a fresh perspective on improving NAS efficiency and robustness. The approach is well-motivated and contextualized within the existing literature, addressing limitations of current methods. The empirical results substantiate the claims of improved performance, demonstrating the method's correctness and scientific rigor. The work contributes new knowledge to the field, particularly in the integration of architecture and dataset encodings within a deep kernel GP surrogate, and holds substantial value for the community by offering a more efficient and adaptable NAS method.",
    "multimodal_rag_review": "**1. Summary**  \nThe paper introduces Transferrable Neural Architecture Search (TNAS), a novel approach to Neural Architecture Search (NAS) that leverages transfer learning to address high computational costs and lack of robustness across datasets. TNAS employs meta-learned Bayesian surrogates to transfer architecture evaluations across datasets, significantly improving efficiency and robustness. Key components include deep-kernel Gaussian Processes for Bayesian Optimization, a Graph Neural Network encoder for architecture representation, and a Transformer-based dataset encoder. The method demonstrates state-of-the-art performance across six computer vision benchmarks, outperforming both black-box and one-shot NAS methods.\n\n**2. Strengths**  \n- The paper presents a novel approach by integrating transfer learning into NAS, which is a significant advancement over traditional NAS methods.\n- The use of meta-learned Bayesian surrogates and deep-kernel Gaussian Processes is innovative and addresses key limitations in existing methods.\n- The experimental results are robust, showing superior performance across multiple datasets and search spaces, which highlights the method's effectiveness and generalizability.\n- The paper adheres to NAS best practices, providing code and detailed experimental protocols, which enhances reproducibility.\n\n**3. Weaknesses**  \n- **Clarity in Methodology**: The explanation of the joint encoding process in Section 3.2 is somewhat dense and could benefit from additional clarification. A more detailed breakdown of how the architecture and dataset encodings are merged would improve understanding.  \n  *Suggestion*: Include a flow diagram or pseudocode to illustrate the joint encoding process clearly.\n\n- **Theoretical Justification**: While the method is empirically validated, the theoretical underpinnings of the meta-learned kernel for Bayesian Optimization in Section 3.1 could be more thoroughly justified.  \n  *Suggestion*: Provide a more detailed theoretical analysis or reference existing literature that supports the choice of the meta-learned kernel.\n\n- **Baseline Comparisons**: Although the paper compares TNAS with several baselines, the inclusion of more recent state-of-the-art NAS methods would strengthen the evaluation.  \n  *Suggestion*: Expand the experimental section to include comparisons with newer NAS methods that have been published recently.\n\n- **Figure Clarity**: Some figures, such as Figure 4 on page 6, have captions that are not fully descriptive, which might lead to confusion about the results being presented.  \n  *Suggestion*: Revise the captions to be more comprehensive, explaining the significance of each result shown.\n\n- **Ablation Study Detail**: The ablation studies in Section 4.5 are insightful but could be expanded to explore the impact of different hyperparameters on the performance of TNAS.  \n  *Suggestion*: Include additional ablation studies focusing on hyperparameter sensitivity to provide a more comprehensive understanding of the method's robustness.\n\n**4. Clarity & Reproducibility**  \n\n  **(a) Textual Clarity**  \n  The paper is generally well-written, with a logical flow of ideas. However, certain sections, particularly those detailing the methodology, could benefit from clearer explanations and more intuitive descriptions. The mathematical notations are well-defined, but the assumptions and limitations could be more explicitly stated to aid comprehension.\n\n  **(b) Figure & Caption Clarity**  \n  Figures are generally effective in illustrating the main claims, but some captions lack detail, which can hinder understanding. Axes and labels are consistent and readable, but ensuring that all figures are self-sufficient with comprehensive captions would enhance clarity.\n\n  **(c) Reproducibility Transparency**  \n  The paper provides a solid foundation for reproducibility, with detailed descriptions of datasets, search spaces, and experimental setups. The availability of code and adherence to NAS best practices further support reproducibility. However, additional details on hyperparameter settings and training times would be beneficial.\n\n**5. Novelty & Significance**  \nThe paper addresses a significant problem in NAS by introducing a transfer learning approach that enhances efficiency and robustness. The integration of meta-learned Bayesian surrogates and deep-kernel Gaussian Processes is novel and contributes new insights to the field. The work is well-motivated and contextualized within the existing literature, providing a substantial contribution to NAS research. The demonstrated state-of-the-art performance across diverse benchmarks underscores the method's significance and potential impact on the community."
}