{
    "paper_id": "6189_certified_training_small_boxes",
    "title": "Certified Training: Small Boxes are All You Need",
    "abstract": "To obtain, deterministic guarantees of adversarial robustness, specialized training methods are used. We propose, SABR, a novel such certified training method, based on the key insight that propagating interval bounds for a small but carefully selected subset of the adversarial input region is sufficient to approximate the worst-case loss over the whole region while significantly reducing approximation errors. We show in an extensive empirical evaluation that SABR outperforms existing certified defenses in terms of both standard and certifiable accuracies across perturbation magnitudes and datasets, pointing to a new class of certified training methods promising to alleviate the robustness-accuracy trade-off.",
    "human_review": "Summary Of The Paper:\nThe authors propose a variant of interval bound propagation (IBP) for certified training using a small region around a preliminary center, e.g. from a PGD attack. Following a theoretical analysis of the employed box propagation, paying special attention to the role of ReLU activations, the authors present a set of experiments showing consistent improvements in terms of both the standard and robust accuracy, along with ablation studies concerning a number of related considerations.\n\nStrength And Weaknesses:\nStrengths\nIntroducing an auxiliary IBP problem admitting better approximations.\nTheoretical analysis of hyperbox growth, with a detailed discussion of the role of ReLU activations following Shi et al. (2021).\nConsistently improved accuracies corroborating the theory, in addition to a valuable ablation study.\n\nWeaknesses\nThe presentation deviates from professional technical writing in a number of critical parts. This leads to unnecessary confusion, as well as a couple inaccurate or unsubstantiated claims:\nImproving on all SOTA methods\nPromising to overcome the robustness-accuracy trade-off\n\nClarity, Quality, Novelty And Reproducibility:\nClarity and quality are very good.\n\nAbstract\nI strongly recommend that the authors refrain from prematurely framing their contribution as novel, as early as the fourth word in the abstract.\nSuch statements are extremely likely to end up harming the contribution. As other reviewers point out, the picture is not as clear cut with respect to randomized smoothing methods.\nI would also recommend that the problem and method are described first, before how it compares to current SOTA.\n\nSection 1\nWhat was meant to be conveyed through the statement \"This yields networks with complex neuron interactions\"? Is that about the ReLU activations? As it stands, it is rather vague and redundant.\nPlease spell out the main \"commonly used settings\" deferring further details to the experiments section.\n\nSection 3\nFirst sentence: we address \"this\" challenge. What challenge?\nIt's not clear what the words \"capture\" and \"actual\" serve, and they appear more than once in the same paragraph.\nI believe \"often still captures the actual worst-case loss\" was meant as \"is a plausible approximation of the worst-case loss\".\nExpressing intuitions is okay, but there's no need to make inaccurate or unsupported claims in the process.\nI strongly recommend that the authors rewrite the sentences following \"Intuitively, often only small subsets of the input are misclassified and only a single point will realize the worst-case loss.\" Those statements almost surely don't hold in general, and need not be settled to communicate intuition in the first place.\nIt would help greatly to include rudimentary experiments to provide better intuitions and empirical evidence to support those motivating observations.\nSecond paragraph: we illustrate \"this intuition\".\nI recommend to start a new paragraph at: \"we tackle this problem\", after clarifying in the first paragraph what the challenge/problem is.\nThis statement \"leading to significantly reduced approximation errors and thus more precise, although not necessarily sound over-approximation of the loss\" is rather too confounding.\nPlease define the propagation of the small region as a proxy or an auxiliary problem to the original problem of propagating the full region. Please include an equation similar to Eq.3 w.r.t. or some other placeholder symbol.\nThen, please explain why this new approximation problem admits a more precise solution, and why it can be understood as a regularization in-between the two extremes.\nThen, please explain how it relates to the original approximation problem, clarifying what was meant by \"not necessarily sound over-approximation\".\nThe paragraph titled \"Selecting the Propagation Region\" is good enough. The leading paragraphs need not say as much, IMHO, and perhaps can be employed to better anticipate the theoretical analysis culminating in Theorem 4.1, and possibly other potential analyses going beyond BOX.\nThe rest of the paper looks good. Only that the repeated claim of overcoming the robustness-accuracy trade-off is too strong, and would at least requires demonstration on a range of learning problems, which the current work does not substantiate.\n\nSummary Of The Review:\nI'm assigning a score of 8 since 7 is no longer available. The revised manuscript addressed my reservations.\n\nCorrectness: 4: All of the claims and statements are well-supported and correct.\nTechnical Novelty And Significance: 4: The contributions are significant, and do not exist in prior works.\nEmpirical Novelty And Significance: 4: The contributions are significant, and do not exist in prior works.\nFlag For Ethics Review: NO.\nRecommendation: 8: accept, good paper\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
    "text_summary": "### Motivation\nAdversarial robustness in neural networks ensures consistent and correct predictions for all inputs within a specified perturbation range, such as an ℓp-norm ball. Certified training methods aim to provide deterministic guarantees against adversarial attacks by approximating the worst-case loss over these regions. However, existing methods face a trade-off: imprecise methods like BOX (interval bound propagation) are computationally efficient but introduce large approximation errors, leading to over-regularization and reduced standard accuracy. On the other hand, precise methods, such as MN-BaB, improve approximation tightness but are computationally expensive and harder to optimize. This paper introduces SABR (Small Adversarial Bounding Regions) to address these challenges by balancing robustness and accuracy.\n\n### Method\nSABR is a novel certified training method that focuses on small, carefully selected subsets of the adversarial input region, called propagation regions. By leveraging imprecise methods like BOX to propagate these subsets, SABR achieves a balance between optimization tractability and precise worst-case loss approximations. The key idea is to replace the maximum over the entire adversarial region \\( B_\\epsilon(x) \\) with a maximum over a smaller subset \\( B_\\tau(x') \\), where \\( \\tau \\) is the size of the subset. This reduces over-approximation errors and avoids the excessive regularization seen in traditional certified training methods.\n\n#### Implementation Details\n1. **Propagation Region Selection**: The propagation region is defined as an ℓp-norm ball \\( B_\\tau(x') \\) with center \\( x' \\) and radius \\( \\tau \\leq \\epsilon - \\|x - x'\\|_p \\). The center \\( x' \\) is chosen using a PGD attack to find the point with the highest loss, ensuring the region includes adversarial examples.\n2. **Propagation Method**: Symbolic propagation methods like BOX or IBP are used to compute an over-approximation of the worst-case loss within \\( B_\\tau(x') \\). Smaller regions (\\( \\tau \\ll 1 \\)) reduce over-approximation errors and improve optimization.\n\n#### Theoretical Insights\nThe paper analyzes the growth of BOX relaxations during propagation, showing that smaller propagation regions accumulate fewer errors. For linear layers, the growth rate is proportional to the ℓ1-norm of the weight matrix, while for ReLU layers, growth depends on input distribution. Empirical results confirm that approximation errors grow super-linearly with input size, emphasizing the importance of SABR's smaller regions.\n\n### Results\nSABR outperforms state-of-the-art certified training methods across multiple datasets and perturbation magnitudes, achieving superior standard and certified accuracies. Key findings include:\n\n1. **CIFAR-10 (ϵ = 2/255)**:\n   - Standard Accuracy: SABR achieves 79.2%, outperforming IBP (66.8%) and CROWN-IBP (71.5%).\n   - Certified Accuracy: SABR reaches 62.8%, surpassing IBP (52.9%) and CROWN-IBP (54.0%).\n\n2. **CIFAR-10 (ϵ = 8/255)**:\n   - Standard Accuracy: SABR achieves 52.4%, slightly better than IBP (48.9%) and CROWN-IBP (46.3%).\n   - Certified Accuracy: SABR achieves 35.1%, outperforming IBP (34.9%) and CROWN-IBP (33.4%).\n\n3. **TinyImageNet (ϵ = 1/255)**:\n   - Standard Accuracy: SABR achieves 28.9%, compared to IBP (25.9%) and CROWN-IBP (25.6%).\n   - Certified Accuracy: SABR achieves 20.5%, outperforming IBP (17.9%) and CROWN-IBP (17.9%).\n\n4. **MNIST**:\n   - At ϵ = 0.1, SABR achieves 99.2% standard accuracy and 98.2% certified accuracy, slightly better than IBP and CROWN-IBP.\n   - At ϵ = 0.3, SABR achieves 98.8% standard accuracy and 93.4% certified accuracy, again outperforming other methods.\n\n#### Ablation Studies\n1. **Propagation Region Size**: Smaller propagation regions (\\( \\lambda \\)) reduce regularization, leading to higher standard and certified accuracies.\n2. **Loss Analysis**: SABR-trained networks exhibit lower robust and standard losses compared to IBP, particularly at smaller \\( \\lambda \\) values.\n3. **ReLU Activation States**: SABR-trained networks have a higher percentage of active ReLUs (35.9%) compared to IBP (26.2%), indicating less over-regularization.\n\n### Conclusion\nSABR introduces a new class of certified training methods that mitigate the robustness-accuracy trade-off by propagating small, adversarially chosen subsets of the input region. This approach reduces over-regularization while maintaining certifiability, achieving state-of-the-art performance in both standard and certified accuracies across benchmarks like MNIST, CIFAR-10, and TinyImageNet. SABR-trained networks exhibit better gradient alignment, reduced approximation errors, and improved ReLU stability, highlighting the importance of balancing regularization and precision in certified training.\n\nThe authors provide open-source code and detailed instructions for reproducing results, ensuring transparency and reproducibility. While SABR significantly advances the field of adversarial robustness, the authors caution that achieving state-of-the-art results does not guarantee sufficient robustness for safety-critical applications.",
    "text_only_review": "#### 1. Summary\nThe paper introduces SABR (Small Adversarial Bounding Regions), a novel certified training method designed to address the trade-off between robustness and accuracy in adversarially robust neural networks. SABR focuses on propagating small, carefully chosen subsets of the adversarial input region to reduce over-approximation errors and avoid excessive regularization. By leveraging imprecise methods like BOX (interval bound propagation) on these smaller regions, SABR achieves a balance between computational efficiency and precise worst-case loss approximations. The method is theoretically motivated, with analyses of error growth during propagation, and empirically validated on datasets such as CIFAR-10, TinyImageNet, and MNIST. SABR demonstrates superior standard and certified accuracies compared to state-of-the-art methods like IBP and CROWN-IBP, with ablation studies providing insights into the impact of propagation region size and loss characteristics.\n\n---\n\n#### 2. Strengths\n1. **Innovative Approach**: The introduction of small adversarial bounding regions is a novel and well-motivated idea that effectively addresses the robustness-accuracy trade-off in certified training.\n2. **Theoretical Insights**: The paper provides a detailed theoretical analysis of error growth during propagation, offering a solid foundation for the proposed method.\n3. **Empirical Validation**: SABR achieves state-of-the-art results across multiple datasets and perturbation magnitudes, demonstrating its effectiveness in improving both standard and certified accuracies.\n4. **Ablation Studies**: The paper includes comprehensive ablation studies that highlight the importance of propagation region size and provide deeper insights into the method's behavior.\n5. **Reproducibility**: The authors provide open-source code and detailed instructions for reproducing the results, ensuring transparency and reproducibility.\n6. **Practical Implications**: The method is computationally efficient compared to precise certified training methods, making it more practical for real-world applications.\n\n---\n\n#### 3. Weaknesses\n1. **Limited Scope of Propagation Region Selection**: While the paper introduces a novel approach to selecting propagation regions, the use of PGD to identify high-loss points may be suboptimal in certain scenarios. The paper does not explore alternative strategies for selecting these regions, which could potentially improve performance further.\n2. **Scalability to Larger Datasets**: While SABR performs well on datasets like CIFAR-10 and TinyImageNet, the paper does not evaluate its scalability to larger datasets or more complex architectures, which are critical for real-world applications.\n3. **Lack of Comparison with Recent Methods**: The paper primarily compares SABR to IBP and CROWN-IBP. While these are strong baselines, the lack of comparison with other recent certified training methods (e.g., randomized smoothing or Lipschitz-based approaches) limits the scope of the evaluation.\n4. **Safety-Critical Applications**: Although the authors acknowledge that SABR may not guarantee sufficient robustness for safety-critical applications, the paper does not provide a detailed discussion on the limitations or potential failure modes of the method in such scenarios.\n5. **Hyperparameter Sensitivity**: The paper does not provide an in-depth analysis of the sensitivity of SABR to hyperparameters, such as the choice of \\( \\tau \\) or the number of PGD steps used for region selection.\n\n---\n\n#### 4. Clarity & Reproducibility\n- **Clarity**: The paper is well-written and structured, with clear explanations of the methodology, theoretical insights, and experimental results. The use of equations and diagrams (if any) effectively supports the narrative.\n- **Reproducibility**: The authors provide open-source code and detailed instructions for reproducing the results, which is a significant strength. However, the paper could benefit from including more details about the computational resources required for training and evaluation.\n\n---\n\n#### 5. Novelty & Significance\n- **Novelty**: The concept of propagating small, adversarially chosen subsets of the input region is a novel contribution to the field of certified training. The theoretical analysis of error growth during propagation further strengthens the novelty of the work.\n- **Significance**: SABR addresses a critical challenge in adversarial robustness by balancing robustness and accuracy, making it a significant contribution to the field. The method's superior performance across multiple benchmarks underscores its practical relevance.\n\n---\n\n#### Overall Recommendation\nThe paper presents a novel, theoretically grounded, and empirically validated approach to certified training that achieves state-of-the-art results. While there are some limitations, such as the lack of comparison with recent methods and limited scalability analysis, these do not detract significantly from the overall quality and contribution of the work. I recommend acceptance, with minor revisions to address the identified weaknesses.",
    "merged_image_path": "temp_cache\\6189_certified_training_small_boxes_merged.png",
    "image_only_review": "#### 1. Summary\nThe paper titled \"Certified Training: Small Boxes Are All You Need\" explores the concept of certified training in neural networks, specifically focusing on the use of small regions (or \"boxes\") to improve robustness and certification of models against adversarial attacks. The authors propose a method that utilizes small boxes for certified training, aiming to enhance the robustness of neural networks while maintaining computational efficiency. The paper presents a theoretical framework, experimental validation, and a comparison with existing methods to demonstrate the effectiveness of the proposed approach.\n\n#### 2. Strengths\n- **Theoretical Framework**: The paper provides a well-structured theoretical foundation for the use of small boxes in certified training, offering clear mathematical formulations and justifications for the proposed method.\n- **Experimental Validation**: The authors conduct extensive experiments to validate their approach, comparing it with existing methods and demonstrating improvements in robustness and certification.\n- **Clarity in Methodology**: The methodology is explained in a detailed manner, making it accessible to readers with a background in machine learning and certified training.\n- **Significant Results**: The proposed method shows significant improvements in robustness and certification metrics compared to baseline methods, highlighting its potential impact on the field.\n\n#### 3. Weaknesses\n- **Limited Scope of Evaluation**: While the experiments are thorough, the evaluation is primarily focused on specific datasets and scenarios. Broader evaluations across diverse datasets and real-world applications could strengthen the claims.\n- **Complexity of Implementation**: The proposed method, while theoretically sound, may be complex to implement in practice, potentially limiting its adoption by practitioners without significant expertise in certified training.\n- **Assumptions and Limitations**: The paper makes certain assumptions about the data and model characteristics that may not hold in all scenarios, which could affect the generalizability of the results.\n\n#### 4. Clarity & Reproducibility\nThe paper is generally well-written and organized, with clear explanations of the theoretical concepts and methodologies. The inclusion of mathematical formulations and detailed descriptions of the experimental setup enhances reproducibility. However, the complexity of the proposed method might pose challenges for practitioners attempting to replicate the results without additional guidance or resources.\n\n#### 5. Novelty & Significance\nThe paper introduces a novel approach to certified training by leveraging small boxes, which is a significant contribution to the field. The method's ability to improve robustness and certification metrics is noteworthy, and it addresses a critical challenge in adversarial machine learning. The significance of the work lies in its potential to influence future research and applications in certified training and robust machine learning. However, the novelty could be further enhanced by exploring broader applications and addressing the limitations in the current evaluation scope.",
    "multimodal_review": "**1. Summary**  \nThe paper introduces SABR (Small Adversarial Bounding Regions), a novel certified training method designed to enhance adversarial robustness in neural networks. SABR focuses on small, carefully selected subsets of the adversarial input region to balance optimization tractability and precise worst-case loss approximations. By leveraging symbolic propagation methods like BOX, SABR reduces over-approximation errors and avoids excessive regularization. The method demonstrates superior performance in both standard and certified accuracies across datasets such as MNIST, CIFAR-10, and TinyImageNet, outperforming existing state-of-the-art methods.\n\n**2. Strengths**  \n- **Innovative Approach**: SABR introduces a novel method for certified training that effectively balances robustness and accuracy by focusing on smaller adversarial regions.\n- **Empirical Performance**: The method outperforms existing state-of-the-art methods in standard and certified accuracies across multiple datasets and perturbation magnitudes.\n- **Theoretical Insights**: The paper provides a thorough theoretical analysis of the growth of BOX relaxations, supporting the empirical findings.\n- **Reproducibility**: The authors provide open-source code and detailed instructions for reproducing the results, enhancing transparency and reproducibility.\n\n**3. Weaknesses**  \n- **Clarity in Method Description**: The description of the propagation region selection in Section 3.1 could be clearer. It would benefit from additional examples or diagrams to illustrate the selection process.\n  - *Suggestion*: Include a step-by-step example or visual aid to clarify the propagation region selection process.\n- **Baseline Comparisons**: While the paper compares SABR with IBP and CROWN-IBP, it lacks a comparison with other recent methods such as MN-BaB in Table 1.\n  - *Suggestion*: Include additional baseline comparisons with recent methods to provide a more comprehensive evaluation.\n- **Ablation Study Details**: The ablation studies in Section 6.1 lack detailed analysis on how different values of \\( \\lambda \\) affect the performance.\n  - *Suggestion*: Provide a more detailed breakdown of the impact of varying \\( \\lambda \\) on both standard and certified accuracies.\n- **Figure Clarity**: Some figures, such as Figure 3, have captions that are not fully self-explanatory and require additional context from the text.\n  - *Suggestion*: Revise captions to be more comprehensive and ensure they can stand alone without requiring extensive reference to the main text.\n- **Discussion of Limitations**: The paper briefly mentions limitations in the conclusion but does not thoroughly discuss potential drawbacks or challenges in implementing SABR.\n  - *Suggestion*: Expand the discussion on limitations, including potential computational costs or scenarios where SABR might underperform.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**  \n  The paper is generally well-written, with clear explanations of the main ideas and methodologies. However, some sections, such as the propagation region selection, could benefit from additional clarity and examples. Mathematical notations are well-defined, and assumptions are clearly stated.\n\n  **(b) Figure & Caption Clarity**  \n  Figures are generally effective in illustrating the main claims, but some captions, like those in Figure 3, could be more self-sufficient. Axes and labels are consistent and readable, but ensuring that captions are comprehensive would improve clarity.\n\n  **(c) Reproducibility Transparency**  \n  The paper provides detailed experimental setups, including datasets, hyperparameters, and algorithmic steps. The availability of open-source code and instructions for reproducing results further enhances reproducibility. However, more detailed ablation studies could improve transparency regarding parameter choices.\n\n**5. Novelty & Significance**  \nSABR presents a novel approach to certified training by focusing on smaller adversarial regions, which is a significant advancement in addressing the robustness-accuracy trade-off. The method is well-motivated and contextualized within the existing literature, offering both theoretical and empirical contributions. The work is significant as it not only improves on existing methods but also provides insights into the importance of balancing regularization and precision in certified training. The results have substantial implications for the field of adversarial robustness, making SABR a valuable contribution to the community.",
    "multimodal_rag_review": "**1. Summary**  \nThe paper introduces SABR (Small Adversarial Bounding Regions), a novel certified training method designed to enhance adversarial robustness without sacrificing accuracy in neural networks. By propagating small, carefully chosen subsets of the adversarial input region, SABR reduces approximation errors inherent in traditional methods like BOX relaxations. Theoretical insights into the growth of BOX relaxations and empirical results on datasets such as MNIST, CIFAR-10, and TinyImageNet demonstrate SABR's superior performance in achieving higher standard and certified accuracies across various perturbation magnitudes.\n\n**2. Strengths**  \n- **Innovative Approach**: SABR offers a novel methodology that effectively balances the trade-off between adversarial robustness and accuracy, a persistent challenge in certified training.\n- **Theoretical Foundation**: The paper provides a detailed theoretical analysis of BOX relaxation growth, which underpins the design and efficacy of SABR.\n- **Empirical Validation**: Extensive experiments on multiple datasets show that SABR outperforms existing certified training methods in both standard and certified accuracies.\n- **Reproducibility**: The authors provide open-source code and detailed instructions, facilitating transparency and reproducibility of their results.\n\n**3. Weaknesses**  \n- **Clarity in Methodology Explanation**: The description of SABR's propagation method in Section 3.2 could benefit from additional clarity, particularly regarding the selection and scaling of the ℓp-norm ball. Suggestion: Include a step-by-step explanation or a flowchart to illustrate the process.\n- **Limited Theoretical Justification for Subselection Ratio**: The choice of the subselection ratio \\( \\lambda \\) in Section 3.2 lacks a thorough theoretical justification. Suggestion: Provide a theoretical analysis or empirical study to justify the selection of \\( \\lambda \\).\n- **Comparison with Baselines**: In Table 1, the paper compares SABR with other methods but does not include a detailed discussion on why certain baselines were chosen over others. Suggestion: Expand the discussion to justify the selection of baselines and consider including additional relevant methods for comparison.\n- **Hyperparameter Tuning Guidance**: The paper introduces new hyperparameters but lacks guidance on their tuning, as seen in Section 4. Suggestion: Include a subsection detailing the impact of hyperparameters and recommended tuning strategies.\n- **Ethical Considerations**: While the paper mentions potential ethical implications, it does not provide a comprehensive discussion on how SABR could be responsibly deployed. Suggestion: Expand on the ethical considerations, particularly in high-stakes applications.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**: The paper is generally well-written, with clear section titles and logical flow. However, certain methodological details, such as the subselection ratio \\( \\lambda \\), require further elaboration. Mathematical notations are well-defined, but assumptions and limitations could be more explicitly stated.\n  \n  **(b) Figure & Caption Clarity**: Figures effectively support the paper's claims, with clear and consistent axes, labels, and legends. However, some captions, like those in Figures 2 and 3, could be more descriptive to stand alone without requiring reference to the main text.\n  \n  **(c) Reproducibility Transparency**: The experimental setup is well-documented, with details on datasets, hyperparameters, and hardware. The inclusion of open-source code enhances reproducibility. However, the paper could benefit from more detailed ablation studies on hyperparameter sensitivity and the impact of different subselection ratios.\n\n**5. Novelty & Significance**  \nSABR represents a significant advancement in the field of certified training by addressing the longstanding challenge of balancing robustness and accuracy. Its novel approach of propagating small subsets of the adversarial input region offers a fresh perspective that could inspire future research. The theoretical insights into BOX relaxation growth and the empirical results demonstrating state-of-the-art performance underscore its potential impact. While the paper could improve in areas such as methodological clarity and ethical considerations, its contributions to robust machine learning are both novel and significant."
}