{
    "paper_id": "6577_learning_to_aggregate_a_parame",
    "title": "Learning to aggregate: A parameterized aggregator to debias aggregation for cross-device federated learning",
    "abstract": "Federated learning (FL) emerged as a novel machine learning setting that enables collaboratively training deep models on decentralized private data. Due to the heterogeneity (non-iidness) of the decentralized data, FL methods (e.g. FedAvg) suffers from unstable and slow convergence. Recent works explain the non-iid problem in FL as the client drift, and deal with it by enforcing regularization at local updates. However, these works neglect the heterogeneity among different communication rounds: the data of sampled candidates at different communication rounds are also of non-iid distribution, and we term it as period drift, which as well as client drift can lead to aggregation bias that degrade convergence. To deal with it, we propose a novel aggregation strategy, named FedPA, that uses a Parameterized Aggregator, as an alternative of averaging. We frame FedPA within a meta-learning setting, and formulates the aggregator as a meta-learner, to learn to aggregate the model parameters of clients. FedPA can directly learn the aggregation bias and well calibrate and control the direction of aggregated parameters to a better direction towards the optimum. Experiments show that FedPA can achieve competitive performances compared with conventional baselines.",
    "human_review": "Summary Of The Paper:\nThe paper introduces a learnable aggregation scheme for federated learning using meta-learning. Specifically, it proposes to generalize the parameters of the aggregator via training on a proxy dataset, thereby addressing what the authors call 'period drift'—a newly identified source of performance degradation in federated learning. The method is evaluated empirically, showing improved accuracy under varying heterogeneity conditions across two datasets.\n\nStrength And Weaknesses:\n\nStrengths:\n- The paper identifies and attempts to address a possible new source of client drift, termed 'period drift'.\n- The proposed meta-learning-based aggregation scheme presents a potentially novel approach to improving model generalization in federated learning.\n\nWeaknesses:\n- The paper does not sufficiently distinguish between conventional client drift and the proposed 'period drift', either theoretically or experimentally.\n- The reliance on a proxy dataset for aggregation significantly limits the practical applicability of the method. Moreover, the approach is conceptually similar to existing knowledge-distillation-based methods such as FedET (Cho et al., 2022) and DS-FL (Itahara et al., 2020). A direct empirical comparison with these methods is missing and necessary to establish novelty.\n- The paper lacks an ablation study exploring how the distribution or quality of the proxy dataset influences model performance.\n- The experimental setup is weak: the datasets and models used are too simplistic to demonstrate robustness or scalability. Evaluations on larger, more realistic datasets such as CIFAR-100 or Stack Overflow would strengthen the claims.\n- The concept of 'period drift'—a central motivation for the work—is vaguely defined and lacks clear mathematical or empirical characterization.\n\nClarity, Quality, Novelty And Reproducibility:\n- **Clarity:** The paper suffers from grammatical errors and imprecise writing. Figures are difficult to read, with small font sizes on the axes.\n- **Quality:** The experimental design and analysis are limited. Key baselines are missing, and the motivation is underdeveloped.\n- **Novelty:** The methodological novelty is limited, as the proposed approach closely resembles existing distillation and meta-learning techniques.\n- **Reproducibility:** Poor. No code or detailed implementation instructions are provided.\n\nSummary Of The Review:\nThe paper proposes a meta-learning-based aggregation scheme for federated learning but fails to adequately define or validate its key motivating concept ('period drift'). The experimental evaluation lacks rigor, ablations, and meaningful baselines, and the overall novelty is minimal given similarities to prior work in distillation-based FL. As it stands, the paper does not meet the threshold for acceptance.\n\nCorrectness: 2: Several of the paper’s claims are incorrect or not well-supported.\nTechnical Novelty And Significance: 1: The contributions are neither significant nor novel.\nEmpirical Novelty And Significance: 2: The contributions are only marginally significant or novel.\nFlag For Ethics Review: NO.\nRecommendation: 3: reject, not good enough\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
    "text_summary": "### Summary of the Paper\n\n#### Motivation\nFederated Learning (FL) is a privacy-preserving machine learning paradigm where decentralized clients collaboratively train a shared model without sharing private data. However, FL faces significant challenges due to the heterogeneity of client data distributions, particularly in cross-device FL with numerous clients (e.g., mobile devices). Two major issues arise in this context:\n1. **Client Drift**: Local updates diverge due to non-iid (non-independent and identically distributed) data, leading to poor convergence and performance degradation.\n2. **Period Drift**: Heterogeneity across communication rounds, where sampled clients in each round have varying data distributions, causes the optimization direction to deviate from the global objective. This amplifies aggregation bias, resulting in slow convergence or oscillations.\n\nExisting methods, such as FedAvg, FedProx, and FedBN, address client drift to some extent but fail to account for period drift, which worsens with increasing non-iidness. This paper identifies period drift as a critical factor affecting FL convergence and proposes a novel solution, FEDPA, to address both client and period drift.\n\n---\n\n#### Method\nThe proposed method, **FEDPA**, introduces a learning-based aggregation strategy within a meta-learning framework to mitigate aggregation bias caused by client and period drift. The key components of FEDPA are:\n\n1. **Parameterized Aggregator**: FEDPA employs a parameterized aggregator, treated as a meta-learner, to dynamically adjust the aggregation process. The aggregator learns to combine client updates in a way that aligns with the global objective, reducing aggregation bias and improving convergence.\n\n2. **Dynamic System View**: FL is modeled as a dynamic system where global model parameters (\\(w_t\\)) evolve based on local updates (\\(\\Delta w_t^k\\)) and aggregation. FEDPA introduces a control variable (\\(u_t^k\\)) for each client to adjust local updates, ensuring they approach the global objective. The controlled system is defined as:\n   \\[\n   w_{t+1} = \\text{aggr}(w_t, \\Delta W_t, \\phi) = \\frac{1}{K} \\sum_{k=1}^K \\left(w_t - \\Delta w_t^k (1 - h(w_t, \\Delta w_t^k, \\phi))\\right)\n   \\]\n   Here, \\(h(\\cdot, \\phi)\\) is a parameterized controller that takes \\(w_t\\) and \\(\\Delta w_t^k\\) as inputs.\n\n3. **Meta-Learning Framework**: The aggregator is trained to minimize aggregation bias by optimizing the performance of the aggregated model on a proxy dataset. The training process involves:\n   - Aggregating client updates into a proxy model.\n   - Evaluating the proxy model's performance on the proxy dataset.\n   - Optimizing the aggregator's parameters (\\(\\phi\\)) to improve the proxy model's performance.\n\n4. **Efficient Architecture**: To address the dimensionality explosion issue, FEDPA uses a bottleneck architecture. Parameters \\(w\\) and \\(\\Delta w\\) are mapped to low-dimensional hidden states, concatenated, and restored to the original dimension through output layers. This design ensures scalability and efficiency.\n\n---\n\n#### Experiments and Results\n\n**Datasets and Models**:\n- **FEMNIST**: A computer vision dataset with non-iid data split by user handwriting. The LeNet5 model is used for classification.\n- **MovieLens 1M**: A recommendation dataset with non-iid user-specific profiles. The DIN model is used for click-through rate (CTR) prediction.\n\n**Experimental Setup**:\n- Non-iidness is controlled using a Dirichlet distribution with varying hyperparameters (\\(\\alpha = 1, 0.1, 0.01\\)).\n- FL training involves 100 communication rounds, with 10% of clients sampled per round. Each client performs 5 local epochs using the Adam optimizer.\n- A small proxy dataset (1% of the training data) is used to train the aggregator.\n\n**Baselines**:\nFEDPA is compared against state-of-the-art methods, including:\n1. **FEDAVG**: Standard FL method using weighted averaging.\n2. **FEDPROX**: Adds a proximal term to handle heterogeneity.\n3. **FEDDF**: Uses ensemble distillation with proxy data.\n4. **FEDMETA**: A federated meta-learning approach with proxy data.\n\n**Results**:\n1. **FEMNIST Dataset**:\n   - FEDPA consistently outperformed baselines across all non-iid settings. For example, at \\(\\alpha = 0.01\\), FEDPA achieved an accuracy of 0.7224, significantly higher than FEDAVG (0.5427) and FEDPROX (0.5478).\n   - FEDPA demonstrated faster and more stable convergence, effectively mitigating the impact of client and period drift.\n\n2. **MovieLens 1M Dataset**:\n   - FEDPA achieved the highest AUC (0.7878) and strong results across other metrics (Hit@5, Hit@10, NDCG@5, NDCG@10).\n   - FEDPA's learning-based aggregator enabled faster convergence compared to FEDDF and FEDMETA, which struggled with overfitting or limited model updates.\n\n3. **Impact of Period Drift**:\n   - Visualizations of label distributions and convergence trajectories confirmed that period drift significantly slows convergence and causes oscillations, especially under extreme non-iid settings (\\(\\alpha = 0.01\\)).\n   - By addressing period drift, FEDPA achieved faster and more stable convergence compared to baselines.\n\n4. **Comparison with Proxy Dataset Methods**:\n   - FEDPA outperformed FEDDF and FEDMETA, which also use proxy datasets, by avoiding direct parameter updates and overfitting risks.\n\n---\n\n#### Conclusion\nThis paper identifies period drift as a critical factor affecting FL convergence and proposes FEDPA as a robust solution. By leveraging a learning-based aggregator within a meta-learning framework, FEDPA effectively mitigates both client and period drift, achieving superior performance and faster convergence across various datasets and non-iid settings. The method's global perspective and adaptive aggregation strategy make it a comprehensive solution to the challenges of FL, outperforming state-of-the-art methods while addressing risks like overfitting.",
    "text_only_review": "### Peer Review for the Paper\n\n#### 1. Summary\nThis paper addresses a critical challenge in Federated Learning (FL): the impact of client and period drift on convergence and performance, particularly in cross-device FL with non-iid data distributions. The authors propose a novel method, FEDPA, which leverages a parameterized aggregator within a meta-learning framework to dynamically adjust the aggregation process and mitigate aggregation bias. FEDPA is evaluated on two datasets (FEMNIST and MovieLens 1M) under varying levels of non-iidness, demonstrating superior performance and faster convergence compared to state-of-the-art FL methods. The paper highlights the importance of addressing period drift, a previously underexplored factor in FL, and provides a robust solution.\n\n---\n\n#### 2. Strengths\n1. **Identification of Period Drift**: The paper makes a significant contribution by identifying and formalizing period drift as a critical factor affecting FL convergence. This is a novel perspective that complements existing work on client drift.\n   \n2. **Innovative Methodology**: The proposed FEDPA method introduces a learning-based aggregation strategy within a meta-learning framework. The use of a parameterized aggregator and dynamic control variables is innovative and well-motivated.\n\n3. **Comprehensive Experiments**: The experimental setup is rigorous, with evaluations conducted on diverse datasets (FEMNIST and MovieLens 1M) and under varying levels of non-iidness. The results convincingly demonstrate FEDPA's superiority over state-of-the-art methods.\n\n4. **Scalability and Efficiency**: The use of a bottleneck architecture to address dimensionality explosion ensures that FEDPA is scalable and computationally efficient, making it suitable for real-world FL scenarios.\n\n5. **Clear Results and Insights**: The paper provides detailed analyses, including visualizations of label distributions and convergence trajectories, to illustrate the impact of period drift and the effectiveness of FEDPA in mitigating it.\n\n6. **Comparison with Proxy Dataset Methods**: The authors thoughtfully compare FEDPA with other proxy dataset methods (FEDDF and FEDMETA), highlighting FEDPA's ability to avoid overfitting and achieve better generalization.\n\n---\n\n#### 3. Weaknesses\n1. **Limited Theoretical Analysis**: While the empirical results are strong, the theoretical justification for the parameterized aggregator and its optimization process is limited. A deeper theoretical analysis of FEDPA's convergence properties and guarantees would strengthen the paper.\n\n2. **Proxy Dataset Dependency**: FEDPA relies on a proxy dataset for training the aggregator. While the authors use only 1% of the training data, the dependency on a proxy dataset may limit the method's applicability in scenarios where such data is unavailable or difficult to obtain.\n\n3. **Scalability to Larger Client Populations**: Although the paper claims scalability, the experiments involve a relatively small subset of clients (10% sampled per round). It would be beneficial to evaluate FEDPA's performance in scenarios with a larger number of clients and more extreme data heterogeneity.\n\n4. **Interpretability of the Aggregator**: The parameterized aggregator is treated as a black box, and its learned behavior is not analyzed in detail. Providing insights into how the aggregator adjusts to mitigate client and period drift would enhance the interpretability and trustworthiness of the method.\n\n5. **Generalization to Other FL Settings**: The paper focuses on cross-device FL with non-iid data. It is unclear how well FEDPA generalizes to other FL settings, such as cross-silo FL or scenarios with adversarial clients.\n\n---\n\n#### 4. Clarity & Reproducibility\n- **Clarity**: The paper is well-written and clearly structured. The motivation, methodology, and experimental results are presented in a logical and coherent manner. The mathematical formulations are precise, and the visualizations effectively support the claims.\n- **Reproducibility**: The experimental setup is described in detail, including datasets, models, hyperparameters, and baselines. However, the paper does not provide access to the code or implementation details for FEDPA. Sharing the code or pseudocode would significantly enhance reproducibility.\n\n---\n\n#### 5. Novelty & Significance\n- **Novelty**: The identification of period drift as a critical factor in FL and the introduction of a learning-based aggregation strategy are novel contributions. The use of a meta-learning framework to optimize the aggregation process is innovative and distinguishes FEDPA from existing methods.\n- **Significance**: The paper addresses a fundamental challenge in FL and provides a comprehensive solution that outperforms state-of-the-art methods. The findings have significant implications for the design of FL algorithms, particularly in cross-device settings with non-iid data.\n\n---\n\n### Overall Assessment\nThis paper makes a strong contribution to the field of Federated Learning by addressing the underexplored issue of period drift and proposing an innovative solution in the form of FEDPA. The method is well-motivated, empirically validated, and demonstrates superior performance across diverse datasets and non-iid settings. However, the paper could be further strengthened by providing a deeper theoretical analysis, addressing the dependency on proxy datasets, and evaluating scalability in larger client populations. Despite these limitations, the paper is a valuable addition to the FL literature and is likely to inspire future research in this area.\n\n**Recommendation**: Accept with minor revisions.",
    "merged_image_path": "temp_cache\\6577_learning_to_aggregate_a_parame_merged.png",
    "image_only_review": "#### 1. Summary\nThe paper presents a novel approach to federated learning (FL) by introducing a parameterized aggregator, termed FedPara, which aims to enhance model aggregation across different devices. The authors address the challenge of data heterogeneity in FL, where data distributions vary significantly across devices, leading to suboptimal model performance. FedPara is designed to learn an aggregation function that adapts to the specific characteristics of each device's data distribution. The paper provides a detailed methodology for implementing FedPara, including mathematical formulations and algorithmic steps. Experimental results demonstrate that FedPara outperforms traditional FL methods in terms of accuracy and robustness across various datasets and scenarios.\n\n#### 2. Strengths\n- **Innovative Approach**: The introduction of a parameterized aggregator is a novel contribution to the field of federated learning, addressing a critical challenge of data heterogeneity.\n- **Comprehensive Methodology**: The paper provides a thorough explanation of the FedPara approach, including clear mathematical formulations and algorithmic steps, which are essential for understanding and replicating the work.\n- **Empirical Validation**: Extensive experiments are conducted on multiple datasets, demonstrating the effectiveness of FedPara in improving model performance compared to traditional FL methods.\n- **Consideration of Privacy**: The paper discusses privacy concerns, which are crucial in the context of federated learning, and suggests that FedPara can be integrated with existing privacy-preserving techniques.\n\n#### 3. Weaknesses\n- **Complexity**: The proposed method introduces additional complexity to the federated learning process, which might be a barrier to its adoption in real-world applications where computational resources are limited.\n- **Limited Discussion on Scalability**: While the paper demonstrates the effectiveness of FedPara on certain datasets, it lacks a detailed discussion on the scalability of the approach to larger and more diverse datasets.\n- **Assumptions on Data Distribution**: The approach assumes that the data distribution characteristics can be effectively captured and utilized for aggregation, which may not hold in all scenarios, particularly in highly dynamic environments.\n\n#### 4. Clarity & Reproducibility\nThe paper is generally well-written and organized, with a logical flow of ideas from the introduction to the conclusion. The methodology section is detailed, providing clear mathematical formulations and pseudocode for the proposed algorithm, which enhances reproducibility. However, the paper could benefit from additional explanations or visual aids to clarify some of the more complex mathematical concepts for readers who may not be specialists in this area.\n\n#### 5. Novelty & Significance\nThe novelty of the paper lies in its introduction of a parameterized aggregator for federated learning, which is a significant departure from traditional aggregation methods. This innovation has the potential to significantly improve the performance of FL systems, particularly in environments with heterogeneous data distributions. The significance of the work is underscored by its potential applications in various domains where federated learning is applicable, such as healthcare, finance, and mobile applications. However, the paper would be strengthened by a more in-depth discussion of potential real-world applications and the implications of the proposed method in these contexts.",
    "multimodal_review": "**1. Summary**  \nThe paper addresses the challenges of client drift and period drift in federated learning (FL), particularly in cross-device settings with non-iid data distributions. It introduces FEDPA, a novel learning-based aggregation strategy that employs a parameterized aggregator within a meta-learning framework to mitigate aggregation bias. FEDPA models FL as a dynamic system, using a control variable to adjust local updates and optimize the aggregation process. The method is evaluated on FEMNIST and MovieLens 1M datasets, demonstrating superior performance and faster convergence compared to state-of-the-art methods like FedAvg and FedProx, particularly under extreme non-iid conditions.\n\n**2. Strengths**  \n- **Innovative Approach**: The introduction of a parameterized aggregator within a meta-learning framework is a novel approach to addressing both client and period drift in FL.\n- **Comprehensive Evaluation**: The paper provides thorough experimental validation on two diverse datasets, showcasing FEDPA's effectiveness across different non-iid settings.\n- **Clear Problem Identification**: The paper clearly identifies period drift as a critical factor in FL, which is often overlooked in existing methods.\n\n**3. Weaknesses**  \n- **Theory Justification**: The theoretical justification for the choice of the parameterized aggregator and its specific architecture could be more robust. The paper should include a more detailed theoretical analysis or justification in Section 3.2.\n- **Baseline Comparisons**: While the paper compares FEDPA against several baselines, it lacks a comparison with more recent methods that might address period drift. Including such comparisons in Section 4.2 would strengthen the evaluation.\n- **Clarity in Methodology**: The explanation of the dynamic system model and the role of the control variable \\(u_t^k\\) in Section 3.2 is somewhat abstract and could benefit from additional clarification or illustrative examples.\n- **Figure Clarity**: Figure 1's caption is not sufficiently descriptive, and the figure itself is complex. Simplifying the diagram or providing a more detailed explanation in the caption would enhance understanding.\n- **Reproducibility Details**: The paper lacks detailed information on hyperparameter tuning and the specific configurations used for the baselines in Section 4.1. Providing a supplementary section with these details would improve reproducibility.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**  \n  The paper is generally well-written, with clear articulation of the problem and proposed solution. However, some sections, particularly the methodology, could benefit from additional clarity and examples to aid understanding. Mathematical notations are mostly well-defined, but assumptions and limitations are not explicitly discussed.\n\n  **(b) Figure & Caption Clarity**  \n  Figures are relevant but could be improved in clarity. Figure 1, in particular, is complex and would benefit from a more detailed caption. Axes and labels are consistent, but some diagrams could be simplified for better comprehension.\n\n  **(c) Reproducibility Transparency**  \n  The paper provides a reasonable level of detail on datasets and experimental setups, but lacks comprehensive information on hyperparameters and baseline configurations. Mentioning code availability or providing a supplementary document with detailed experimental settings would enhance reproducibility.\n\n**5. Novelty & Significance**  \nThe paper presents a novel approach to addressing period drift in federated learning, a problem that has not been extensively explored in the literature. The introduction of a parameterized aggregator within a meta-learning framework is a significant contribution, offering a new perspective on aggregation strategies in FL. The work is well-motivated and contextualized within the existing literature, and the empirical results substantiate the claims of improved performance and convergence. The significance of the work lies in its potential to improve the robustness and efficiency of FL systems, particularly in non-iid settings, making it a valuable contribution to the field.",
    "multimodal_rag_review": "**1. Summary**  \nThe paper introduces FEDPA, a novel meta-learning-based aggregation strategy for federated learning (FL) that addresses the challenges of client drift and period drift in non-iid data settings. FEDPA employs a parameterized aggregator trained on a proxy dataset to adaptively mitigate aggregation bias, enhancing convergence and performance in FL. The approach is validated through experiments on FEMNIST and MovieLens 1M datasets, demonstrating superior performance over baseline methods like FEDAVG and FEDPROX, particularly in scenarios with high non-iidness.\n\n**2. Strengths**  \n- The paper addresses a significant challenge in federated learning, namely the dual issues of client drift and period drift, which are crucial for improving model convergence and performance in non-iid settings.\n- The introduction of a meta-learning-based parameterized aggregator is innovative, providing a dynamic and adaptive approach to aggregation that outperforms traditional static methods.\n- The empirical results are robust, showcasing the effectiveness of FEDPA across different datasets and metrics, with clear improvements over existing baseline methods.\n- The use of a proxy dataset for training the aggregator is a practical approach that balances computational efficiency with performance gains.\n\n**3. Weaknesses**  \n- **Clarity of Methodology**: The explanation of the meta-learning framework and its integration into the aggregation process is somewhat dense and could benefit from clearer exposition. Specifically, Section 3.2 could include more intuitive explanations or visual aids to enhance understanding. Consider adding a flowchart or diagram to illustrate the meta-learning process.\n- **Theoretical Justification**: While the empirical results are strong, the paper lacks a rigorous theoretical analysis of why the meta-learning-based approach effectively mitigates period drift. A more detailed theoretical discussion in Section 3.1 would strengthen the paper's claims. Consider including theoretical insights or proofs to support the observed empirical phenomena.\n- **Baseline Comparisons**: The choice of baselines, while comprehensive, could be expanded to include more recent methods that address similar challenges, such as personalized federated learning approaches. In Section 4.1, consider adding comparisons with newer methods to provide a broader context for FEDPA's performance.\n- **Proxy Dataset Details**: The selection and role of the proxy dataset are crucial to FEDPA's success, yet the paper provides limited discussion on how the proxy dataset is chosen and its potential impact on privacy. Section 3.3 could benefit from a more detailed explanation of the proxy dataset's selection criteria and its implications.\n- **Figure Clarity**: Some figures, such as Figure 3, have captions that are not sufficiently descriptive, and the visual elements could be clearer. Ensure that all figures are self-contained with comprehensive captions and that the visual elements are easily interpretable.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**: The paper is generally well-organized, with a logical flow from problem identification to solution and results. However, some sections, particularly those detailing the methodology, could benefit from clearer explanations and additional context to aid comprehension. Definitions and assumptions should be explicitly stated to avoid ambiguity.\n\n  **(b) Figure & Caption Clarity**: While the figures are generally informative, some captions lack detail, and the figures themselves could be made clearer. For instance, Figure 3 should have a more descriptive caption explaining the axes and the significance of the visualized data. Ensure that all figures are fully self-explanatory and that their relevance to the text is clear.\n\n  **(c) Reproducibility Transparency**: The paper provides a good level of detail regarding experimental setups, including datasets, hyperparameters, and baseline methods. However, it lacks explicit mention of code availability, which is crucial for reproducibility. Including a link to the code repository or detailed pseudocode would enhance reproducibility. Additionally, more information on the random seeds and hardware used would be beneficial.\n\n**5. Novelty & Significance**  \nThe paper presents a novel approach to addressing a well-known problem in federated learning, namely the challenges posed by non-iid data distributions. The use of a meta-learning-based aggregator is a significant contribution, offering a dynamic and adaptive solution that outperforms traditional methods. The work is well-motivated and contextualized within the existing literature, and the empirical results substantiate the claims made. The significance of the work lies in its potential to improve FL performance in real-world applications, particularly in cross-device settings where data heterogeneity is prevalent. Overall, the paper contributes valuable insights and methodologies to the field of federated learning, with implications for both theoretical advancements and practical implementations."
}