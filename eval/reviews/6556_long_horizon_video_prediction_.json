{
    "paper_id": "6556_long_horizon_video_prediction_",
    "title": "Long-horizon video prediction using a dynamic latent hierarchy ",
    "abstract": "The task of video prediction and generation is known to be notoriously difficult, with the research in this area largely limited to short-term predictions. Though plagued with noise and stochasticity, videos consist of features that are organised in a spatiotemporal hierarchy, different features possessing different temporal dynamics. In this paper, we introduce Dynamic Latent Hierarchy (DLH) -- a deep hierarchical latent model that represents videos as a hierarchy of latent states that evolve over separate and fluid timescales. Each latent state is a mixture distribution with two components, representing the immediate past and the predicted future, causing the model to learn transitions only between sufficiently dissimilar states, while clustering temporally persistent states closer together. Using this unique property, DLH naturally discovers the spatiotemporal structure of a dataset and learns disentangled representations across its hierarchy. We hypothesise that this simplifies the task of modeling temporal dynamics of a video, improves the learning of long-term dependencies, and reduces error accumulation. As evidence, we demonstrate that DLH outperforms state-of-the-art benchmarks in video prediction, is able to better represent stochasticity, as well as to dynamically adjust its hierarchical and temporal structure. Our paper shows, among other things, how progress in representation learning can translate into progress in prediction tasks.",
    "human_review": "Summary Of The Paper:\nThe paper presents a method for hierarchical representation learning of spatiotemporal features in long-term video prediction, called Dynamic Latent Hierarchy (DLH). The proposed model distinguishes between features that change and those that remain static across video sequences. DLH can handle multiple moving objects at different speeds while differentiating them from a static background. Its advantages include long-term video prediction capability, improved modeling of stochasticity, and dynamically adaptive latent hierarchies. DLH outperforms existing baselines on the Moving MNIST, KTH Action, and DML Mazes datasets.\n\nStrength And Weaknesses:\n\nStrengths:\n- The paper is well written, and the ideas are clearly explained and easy to follow.\n- The problem is well-motivated and contextualized with a strong review of related literature.\n- The methods section provides both intuitive and formal explanations for the design choices, which are empirically supported.\n- The authors attempt to interpret the learned hierarchical levels semantically in the experiments.\n- Experiments are thoughtfully constructed given the datasets used, and the results are convincing.\n- Figures are clear and effectively illustrate DLH’s benefits, particularly Fig. 5, which provides helpful insight into the learned hierarchy.\n\nWeaknesses:\n- The datasets used (e.g., Moving MNIST, KTH Action) are relatively simple and lack complexity, limiting the demonstration of DLH’s full potential to handle multiple dynamic objects or complex real-world motion. Evaluation on more challenging datasets such as Waymo Open Dataset, NuScenes, or KITTI would strengthen the claims.\n- The stochastic modeling capability is primarily evaluated on a toy dataset with random color changes. The paper does not discuss whether DLH can handle multimodal futures (e.g., multiple plausible outcomes for the same input sequence), which is crucial for complex video prediction tasks.\n- The paper would benefit from visual comparisons to baseline methods (e.g., adding baseline outputs to Fig. 4).\n- In Fig. 5, the disentanglement between hierarchy levels for the KTH dataset is not clearly demonstrated.\n- A deterministic baseline comparison in Table 1 could clarify whether stochastic modeling is truly necessary for the evaluated datasets.\n- The paper lacks statistical significance reporting for performance improvements in Table 1.\n- Some visual results (e.g., Fig. 6) are ambiguous — it is unclear what specific issues occur in baseline models like CW-VAE.\n- Additional explanation of values in Table 3 would be helpful.\n\nMinor Comments and Typos:\n- Some figures (e.g., Fig. 2) are confusing, potentially missing temporal indices.\n- Notation inconsistencies appear in Sec. 2.2 and Eq. 3; certain parameters are undefined or dropped.\n- Eq. 3 is missing a period; Eq. 8 derivation from Eq. 7 should be shown in the appendix.\n- Several grammatical issues, missing periods in captions, and inconsistent citation formatting throughout.\n- Clarify whether the first hierarchical level always has a fixed structure and whether past context frames are included in visualizations (e.g., Fig. 4).\n\nClarity, Quality, Novelty And Reproducibility:\n\nClarity: The presentation is overall strong, with detailed explanations and helpful visualizations. A few notational inconsistencies should be fixed.\nQuality: High. The experimental setup is thorough for the given datasets, and the results are well-presented.\nNovelty: Moderate to high. The idea of dynamically adaptive latent hierarchies for video prediction introduces a meaningful advancement beyond prior hierarchical VAEs and stochastic video models.\nReproducibility: Moderate. While the methodology is clearly explained, the absence of released code hinders full reproducibility.\n\nSummary Of The Review:\nThis is a well-written and thoughtfully executed paper that introduces a dynamic hierarchical framework for video prediction. The proposed DLH method shows solid improvements over baselines and provides interpretable hierarchical representations. The main limitations lie in the simplicity of the datasets and the lack of complex, real-world evaluations. Addressing these would significantly strengthen the contribution. Overall, the reviewer leans toward acceptance.\n\nCorrectness: 4: All of the claims and statements are well-supported and correct.\nTechnical Novelty And Significance: 3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.\nEmpirical Novelty And Significance: 3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.\nFlag For Ethics Review: NO.\nRecommendation: 6: marginally above the acceptance threshold\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
    "text_summary": "### Long-Horizon Video Prediction Using a Dynamic Latent Hierarchy\n\n#### Motivation\nVideo prediction, particularly over long horizons, is a challenging task due to the inherent noise, stochasticity, and complex temporal dynamics of video data. These challenges are exacerbated by error accumulation in sequential predictions, which often limits research to short-term horizons. Videos naturally exhibit a spatiotemporal hierarchy, where different features evolve at varying timescales (e.g., moving objects versus static backgrounds). While hierarchical latent models have shown promise in capturing such structures, existing methods often fail to fully exploit temporal hierarchies or adapt dynamically to the dataset's structure. This paper addresses these gaps by introducing a novel hierarchical generative model for long-term video prediction.\n\n---\n\n#### Method: Dynamic Latent Hierarchy (DLH)\nThe proposed **Dynamic Latent Hierarchy (DLH)** is a hierarchical generative model designed to address the challenges of long-horizon video prediction. It represents videos as a hierarchy of latent states evolving over flexible timescales, enabling disentangled and meaningful representations of spatiotemporal dynamics. Key features of DLH include:\n\n1. **Hierarchical Latent States**:\n   - Latent states are modeled as a temporal mixture of two Gaussian components: one representing the static past (static prior) and the other representing dynamic changes (change prior).\n   - An indicator variable \\( e_t \\) determines whether the state \\( s_t \\) should remain static or transition to a new state, allowing the model to cluster temporally persistent states and transition only when significant changes occur.\n\n2. **Dynamic Temporal Hierarchy**:\n   - DLH learns the spatiotemporal structure of datasets in an unsupervised manner, dynamically adapting its hierarchy to the temporal dynamics of the data.\n   - A nested timescale constraint ensures that higher levels of the hierarchy represent progressively slower-changing features, while lower levels capture faster dynamics.\n\n3. **Non-Parametric Inference**:\n   - The model employs a non-parametric approach to estimate the discrete posterior distribution over the temporal Gaussian mixture components, improving its ability to represent stochasticity in video data.\n\n4. **Training and Optimization**:\n   - The model is trained using a variational lower bound (ELBO) with three components: data likelihood, KL divergence over \\( e_t \\) (to learn static and change priors), and KL divergence over \\( s_t \\) (to regularize the latent space).\n   - A gradual increase in the KL loss scaling parameter \\( \\beta \\) during training allows the model to prioritize accurate reconstructions before constraining latent complexity.\n\n5. **Architecture**:\n   - DLH uses a combination of convolutional layers for encoding and decoding, GRUs for temporal modeling, and fully connected MLP layers for posterior and prior state estimation.\n   - The model is parameter-efficient, with only 7 million parameters, and is trained on a Tesla V100 GPU over three days.\n\n---\n\n#### Experiments and Results\nDLH was evaluated on several datasets, including **Moving MNIST**, **KTH Action**, **DeepMind Lab Mazes**, and a toy **Moving Ball** dataset, and compared against state-of-the-art benchmarks such as CW-VAE, VTA, and LMC-Memory. Key findings include:\n\n1. **Prediction Performance**:\n   - DLH outperformed existing methods in long-term video prediction, achieving higher Structural Similarity Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR) scores.\n   - For example, on Moving MNIST, DLH achieved SSIM of 0.84 and PSNR of 24.7, surpassing CW-VAE (0.80, 22.0), VTA (0.77, 22.41), and LMC-Memory (0.83, 23.44).\n\n2. **Hierarchical Disentanglement**:\n   - DLH effectively discovered and disentangled spatiotemporal structures, clustering temporally persistent states and dynamically adjusting its hierarchy.\n   - Experiments demonstrated that higher levels in the hierarchy captured slower-changing features (e.g., background details), while lower levels encoded faster dynamics (e.g., object motion).\n\n3. **Stochasticity Representation**:\n   - DLH demonstrated robustness to stochasticity, such as random object movements or color changes, outperforming benchmarks in datasets with high temporal randomness (e.g., Moving Ball dataset).\n\n4. **Parameter Efficiency**:\n   - Despite using significantly fewer parameters (7M) compared to LMC-Memory (34M) and CW-VAE (12M), DLH maintained superior performance.\n\n5. **Hierarchical Adaptation**:\n   - DLH naturally collapsed unused hierarchical levels, as evidenced by low KL divergence values for higher levels. This behavior suggests that the model dynamically adjusts its complexity based on the dataset.\n\n6. **Qualitative Analysis**:\n   - Visual comparisons showed that DLH preserved critical contextual information (e.g., digit positions in Moving MNIST, maze configurations in DML Mazes) while accurately predicting long sequences.\n\n---\n\n#### Conclusion\nThe **Dynamic Latent Hierarchy (DLH)** introduces a novel approach to long-horizon video prediction by leveraging hierarchical generative modeling and temporal abstraction. By learning disentangled hierarchical representations and dynamically adapting to the temporal structure of datasets, DLH simplifies the modeling of complex video dynamics, reduces error accumulation, and improves prediction quality. Key contributions include:\n\n1. **Hierarchical Latent Space**:\n   - DLH organizes latent variables hierarchically, enabling spatiotemporal disentanglement and temporal abstraction.\n\n2. **Dynamic Complexity Regulation**:\n   - The model dynamically adjusts its structural complexity, collapsing unused hierarchical levels to improve computational efficiency.\n\n3. **Robustness to Stochasticity**:\n   - DLH generates coherent and sharp predictions even in datasets with high temporal randomness.\n\n4. **State-of-the-Art Performance**:\n   - DLH outperformed existing benchmarks across multiple datasets, achieving superior SSIM and PSNR scores while using fewer parameters.\n\nThis work highlights the potential of hierarchical generative models in advancing video prediction tasks, with implications for applications such as model-based reinforcement learning and planning. Future work could explore relaxing constraints on hierarchical structure and further improving the sharpness of predictions.",
    "text_only_review": "#### 1. Summary\nThe paper introduces the **Dynamic Latent Hierarchy (DLH)**, a novel hierarchical generative model for long-horizon video prediction. DLH addresses challenges such as error accumulation, stochasticity, and the complex temporal dynamics of video data by leveraging a dynamically adaptive hierarchical latent space. The model organizes latent states hierarchically, with higher levels capturing slower-changing features and lower levels encoding faster dynamics. Key innovations include a dynamic temporal hierarchy, a non-parametric approach to stochasticity representation, and a parameter-efficient architecture. The model demonstrates state-of-the-art performance on multiple datasets, achieving superior SSIM and PSNR scores while maintaining computational efficiency.\n\n#### 2. Strengths\n1. **Innovative Approach**:\n   - The introduction of a dynamic temporal hierarchy that adapts to the dataset's spatiotemporal structure is a significant contribution, addressing key limitations of existing hierarchical models.\n   - The use of a temporal Gaussian mixture model with an indicator variable \\( e_t \\) for clustering temporally persistent states is novel and well-motivated.\n\n2. **State-of-the-Art Performance**:\n   - DLH achieves superior quantitative results (SSIM, PSNR) compared to benchmarks across diverse datasets, demonstrating its robustness and generalizability.\n\n3. **Hierarchical Disentanglement**:\n   - The model effectively disentangles spatiotemporal dynamics, with qualitative and quantitative evidence supporting its ability to cluster and represent features at different timescales.\n\n4. **Parameter Efficiency**:\n   - DLH achieves competitive performance with significantly fewer parameters than competing methods, highlighting its computational efficiency.\n\n5. **Comprehensive Evaluation**:\n   - The experiments are thorough, covering multiple datasets with varying levels of complexity and stochasticity. The inclusion of qualitative analyses and ablation studies strengthens the empirical validation.\n\n6. **Dynamic Complexity Regulation**:\n   - The model's ability to collapse unused hierarchical levels dynamically is an elegant solution to avoid overfitting and reduce computational overhead.\n\n#### 3. Weaknesses\n1. **Limited Analysis of Failure Cases**:\n   - While the paper highlights the strengths of DLH, it does not provide sufficient analysis of its limitations or scenarios where it may underperform. For example, how does DLH handle extremely high-dimensional video data or datasets with highly irregular temporal dynamics?\n\n2. **Sharpness of Predictions**:\n   - The paper acknowledges that improving the sharpness of predictions is an area for future work. However, it does not provide a detailed discussion of why this limitation exists or how it could be addressed.\n\n3. **Model Complexity**:\n   - While the model is parameter-efficient, the architecture and training process (e.g., dynamic temporal hierarchy, non-parametric inference) are relatively complex. This could pose challenges for reproducibility and adoption by the broader community.\n\n4. **Evaluation Metrics**:\n   - The reliance on SSIM and PSNR as primary metrics, while standard, may not fully capture the perceptual quality of long-horizon video predictions. Additional metrics or user studies could provide a more holistic evaluation.\n\n5. **Generality of Hierarchical Adaptation**:\n   - The dynamic adjustment of hierarchical levels is dataset-dependent, but the paper does not explore whether this behavior generalizes across all types of video data or how it performs in edge cases (e.g., videos with abrupt changes in dynamics).\n\n#### 4. Clarity & Reproducibility\n- **Clarity**:\n   - The paper is well-written and provides a clear explanation of the proposed method, including its motivation, architecture, and training process. The inclusion of mathematical formulations and diagrams aids understanding.\n   - However, some technical details, such as the specific implementation of the non-parametric inference mechanism, could be elaborated further.\n\n- **Reproducibility**:\n   - The description of the architecture, training procedure, and hyperparameters is reasonably detailed, but the paper does not provide code or pseudocode, which would significantly enhance reproducibility.\n   - The lack of explicit details on dataset preprocessing and evaluation protocols may hinder exact replication of the results.\n\n#### 5. Novelty & Significance\n- **Novelty**:\n   - The proposed dynamic temporal hierarchy and the use of a temporal Gaussian mixture model with an indicator variable \\( e_t \\) are novel contributions to hierarchical generative modeling.\n   - The dynamic adjustment of hierarchical levels based on dataset complexity is a unique feature that distinguishes DLH from existing methods.\n\n- **Significance**:\n   - The work addresses a critical challenge in video prediction—long-horizon forecasting—by mitigating error accumulation and improving temporal abstraction.\n   - The model's ability to disentangle spatiotemporal dynamics has implications beyond video prediction, potentially benefiting fields such as model-based reinforcement learning, planning, and robotics.\n\n#### Overall Recommendation\nThe paper presents a significant contribution to the field of video prediction, with strong theoretical foundations, empirical validation, and practical implications. While there are areas for improvement, such as sharper predictions and better reproducibility, the strengths of the work outweigh its weaknesses. I recommend **acceptance** at a top-tier venue, provided the authors address the concerns regarding failure cases, evaluation metrics, and reproducibility.",
    "merged_image_path": "temp_cache\\6556_long_horizon_video_prediction__merged.png",
    "image_only_review": "#### 1. Summary\nThe paper presents a novel approach for long-horizon video prediction using a dynamic latent hierarchy. The authors propose a generative model that captures the temporal dependencies in video sequences by utilizing a hierarchical structure of latent variables. The model is designed to improve the prediction quality over extended time horizons by dynamically adjusting the latent hierarchy based on the input sequence. The paper includes a comprehensive evaluation of the proposed method on several benchmark datasets, demonstrating its superior performance compared to existing state-of-the-art methods.\n\n#### 2. Strengths\n- **Innovative Approach**: The introduction of a dynamic latent hierarchy for video prediction is a novel concept that addresses the challenges of long-horizon predictions effectively.\n- **Comprehensive Evaluation**: The authors provide extensive experimental results on multiple datasets, showcasing the robustness and generalizability of their model.\n- **Theoretical Foundation**: The paper is well-grounded in theory, with detailed derivations and explanations of the model's components and their interactions.\n- **Performance**: The proposed method outperforms existing approaches in terms of prediction accuracy and temporal coherence, as evidenced by the quantitative results.\n\n#### 3. Weaknesses\n- **Complexity**: The model's complexity might pose challenges for practical implementation, especially in real-time applications where computational resources are limited.\n- **Limited Ablation Studies**: While the paper includes some ablation studies, further analysis could be provided to better understand the contribution of each component of the model.\n- **Generalization to Diverse Video Types**: The datasets used for evaluation may not cover all types of video content, and it is unclear how well the model generalizes to other domains or more complex scenes.\n\n#### 4. Clarity & Reproducibility\nThe paper is generally well-written and structured, with clear explanations of the methodology and results. However, some sections, particularly those involving mathematical derivations, could benefit from additional clarity or simplification for readers less familiar with the technical details. The authors provide sufficient information regarding the experimental setup, including hyperparameters and training procedures, which aids in reproducibility. The inclusion of code or pseudocode would further enhance reproducibility.\n\n#### 5. Novelty & Significance\nThe proposed dynamic latent hierarchy represents a significant advancement in the field of video prediction, offering a new perspective on handling long-horizon dependencies. This approach has the potential to influence future research in video prediction and related areas, such as reinforcement learning and autonomous systems. The novelty of the method, combined with its demonstrated performance improvements, underscores its importance and potential impact on the field.",
    "multimodal_review": "**1. Summary**  \nThe paper introduces a novel hierarchical generative model named Dynamic Latent Hierarchy (DLH) for long-horizon video prediction. DLH models videos as a hierarchy of latent states evolving over flexible timescales, allowing for disentangled and meaningful representations of spatiotemporal dynamics. The model employs a non-parametric approach to estimate the discrete posterior distribution over temporal Gaussian mixture components, enhancing its ability to represent stochasticity. Evaluated on datasets such as Moving MNIST and KTH Action, DLH outperforms state-of-the-art benchmarks in terms of SSIM and PSNR scores, demonstrating robustness to stochasticity and parameter efficiency.\n\n**2. Strengths**  \n- The paper addresses a significant challenge in video prediction by focusing on long-horizon scenarios, which are often neglected due to error accumulation issues.\n- DLH's hierarchical approach effectively captures the spatiotemporal dynamics, offering a novel method for disentangling and representing video data.\n- The model demonstrates superior performance compared to existing benchmarks, achieving higher SSIM and PSNR scores across various datasets.\n- DLH is parameter-efficient, using significantly fewer parameters than comparable models while maintaining or exceeding their performance.\n\n**3. Weaknesses**  \n- **Clarity in Methodology Explanation**: The description of the hierarchical latent states and the role of the indicator variable \\( e_t \\) in Section 2.1 could be more detailed. Suggestion: Expand on the mechanism by which \\( e_t \\) influences state transitions with a step-by-step example.\n- **Baseline Comparisons**: The paper lacks a comparison with some recent methods in video prediction, such as those using transformers. Suggestion: Include a comparison with transformer-based models in Table 1 to provide a broader context of DLH's performance.\n- **Ablation Studies**: Section 4.4 mentions hierarchical adaptation but lacks an ablation study to quantify the impact of different hierarchical levels on performance. Suggestion: Conduct and include an ablation study focusing on the contribution of each hierarchical level.\n- **Figure Clarity**: Figure 3's caption is ambiguous regarding the specific dynamics being illustrated. Suggestion: Clarify which aspects of the temporal dynamics each part of the figure is meant to represent.\n- **Code and Data Availability**: There is no mention of code or data availability for reproducibility. Suggestion: Include a statement regarding the availability of code and datasets used for experiments.\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**  \n  The paper is generally well-written, with a logical flow of ideas and clear articulation of the problem and proposed solution. However, some sections, particularly those detailing the methodology, could benefit from additional clarity and examples to aid understanding.\n\n  **(b) Figure & Caption Clarity**  \n  Figures are generally well-designed and support the paper's claims, but some captions, such as Figure 3, could be more descriptive to enhance comprehension. Axes and labels are consistent and readable.\n\n  **(c) Reproducibility Transparency**  \n  The paper provides a detailed description of the experimental setup, including datasets and model parameters. However, it lacks explicit mention of code and data availability, which is crucial for reproducibility. An ablation study on the hierarchical structure's impact would further enhance transparency.\n\n**5. Novelty & Significance**  \nThe paper presents a novel approach to video prediction by leveraging hierarchical generative modeling, which is well-motivated and contextualized within the existing literature. The introduction of a dynamic latent hierarchy is a significant contribution, offering a new perspective on disentangling spatiotemporal dynamics in video data. The work is substantiated by rigorous empirical evaluation, demonstrating its robustness and efficiency. The significance lies in its potential applications in fields requiring long-term video prediction, such as model-based reinforcement learning and planning. Overall, the paper contributes valuable insights and methodologies to the video prediction community.",
    "multimodal_rag_review": "**1. Summary**  \nThe paper presents Dynamic Latent Hierarchies (DLH), a novel hierarchical latent-variable generative model aimed at improving long-horizon video prediction. DLH addresses the challenges of noise, stochasticity, and complex temporal dynamics by organizing video features into a hierarchy of latent states that evolve over flexible timescales. The model employs a temporal mixture of Gaussians to manage state transitions, reducing error accumulation and computational complexity. Experimental results demonstrate that DLH outperforms state-of-the-art models in both quantitative metrics and qualitative assessments across various datasets, showcasing its ability to maintain contextual consistency and handle temporal stochasticity effectively.\n\n**2. Strengths**  \n- **Innovative Approach**: DLH introduces a novel hierarchical structure that effectively models spatiotemporal dynamics, which is a significant advancement in the field of video prediction.\n- **Performance**: The model consistently outperforms existing benchmarks in key metrics such as SSIM and PSNR, indicating its superior ability to predict long-horizon video sequences.\n- **Computational Efficiency**: By dynamically adjusting its hierarchical structure and pruning unused levels, DLH achieves computational efficiency without compromising prediction quality.\n- **Handling Stochasticity**: The use of temporal mixtures of Gaussians allows DLH to effectively model stochastic elements in video sequences, enhancing its robustness in diverse scenarios.\n\n**3. Weaknesses**  \n- **Lack of Novelty in Certain Components**: While the hierarchical approach is innovative, some components such as the use of GRUs and convolutional layers are standard (Section 3.1). Consider integrating more novel architectural elements or justifying the choice of these standard components in the context of DLH.\n- **Limited Discussion on Limitations**: The paper briefly mentions limitations regarding prediction sharpness and scalability (Section 7), but lacks an in-depth discussion. Expanding on these limitations and potential solutions could provide a more balanced view.\n- **Insufficient Baseline Comparisons**: Although DLH is compared with several models, the paper does not include comparisons with more recent advancements in video prediction, such as diffusion models (Section 6). Including these comparisons would strengthen the claims of superiority.\n- **Clarity in Methodology Description**: The explanation of the temporal module and its integration with the hierarchical structure is somewhat unclear (Section 4.2). Providing a more detailed description or a schematic diagram could enhance understanding.\n- **Qualitative Results Presentation**: While qualitative results are provided, the presentation could be improved by including more diverse examples and clearer annotations to highlight the model's strengths (Section 6.2).\n\n**4. Clarity & Reproducibility**  \n  **(a) Textual Clarity**: The paper is generally well-written, with clear explanations of the main ideas and methodologies. However, some sections, particularly those describing the temporal module, could benefit from additional clarity and detail. The assumptions and limitations are briefly mentioned but could be expanded for better transparency.\n\n  **(b) Figure & Caption Clarity**: Figures are generally well-designed and support the text effectively. However, some captions could be more descriptive to ensure they are self-sufficient. For instance, Figure 3 could include more detailed explanations of the depicted processes.\n\n  **(c) Reproducibility Transparency**: The paper provides a reasonable level of detail regarding experimental setups, including datasets and evaluation metrics. However, more information on hyperparameters, hardware specifications, and random seeds would enhance reproducibility. The availability of code and data is not mentioned, which is crucial for reproducibility.\n\n**5. Novelty & Significance**  \nDLH presents a significant advancement in video prediction by introducing a dynamic hierarchical structure that effectively models long-term dependencies and stochasticity. The approach is well-motivated and contextualized within the existing literature, addressing key limitations of prior models. The empirical results substantiate the claims of improved performance, demonstrating the model's potential impact on the field. While the novelty of some components could be enhanced, the overall contribution of DLH is substantial, providing new insights and methodologies for handling complex video dynamics."
}